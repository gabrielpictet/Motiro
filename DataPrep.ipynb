{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0ae26c-d722-4354-9f63-12aa10ae09ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "openAI_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openAI_api_key:\n",
    "    print(\"API key found\")\n",
    "else:\n",
    "    print(\"API key not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9937a37-f270-405c-a095-c3d80bb2b196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Attempt to read the uploaded .txt file with an alternative encoding\n",
    "file_path = 'C:/Users/gabriel.pictet/Documents/Gabriel/REAL/Moti/Moti data/answers-volunteers.txt'\n",
    "df = pd.read_csv(file_path, sep=\",\", encoding='ISO-8859-1')\n",
    "#alternative encoding not working: df = pd.read_csv(file_path, sep=\",\", encoding='cp1252')\n",
    "# Display the first few rows of the dataframe to verify successful loading\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24ff19f8-5a05-4840-9eca-d93d552ce007",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open the Raw Moti Data CSV file as sent by CE\n",
    "#          Volunteers:  answers-volunteers.csv\n",
    "#          staff: answers-staff.csv  (see below)\n",
    "# The csv file is corrupted by MS Excel so it needs to be opened in notepad and saved as a .txt file\n",
    "\n",
    "df = pd.read_csv(\"C:/Users/gabriel.pictet/Documents/Gabriel/REAL/Moti/Moti data/answers-volunteers.txt\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4f104e3-a215-44de-a515-e2c411b9615b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STAFF: Open the Raw Moti Data CSV file as sent by CE\n",
    "\n",
    "df = pd.read_csv(\"C:/Users/gabriel.pictet/Documents/Gabriel/REAL/Moti/Moti data/answers-staff.txt\", sep=\",\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2b3cb9-7e70-47d1-9cec-1258fe54e0e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 1\n",
    "# STEP 1.1 Create country variable based on Team Name\n",
    "# Assigns a country to each team\n",
    "# Prompts user to allocate country to new teams\n",
    "# and updates country_team_dictionary Runs allocation\n",
    "# Use this snippet for VOLUNTEERS and STAFF datasets\n",
    "\n",
    "with open(\"team_country_allocation.py\") as file:\n",
    "    exec(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1504c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "# STEP 1.2 - dropping illigitimate ballots\n",
    "\n",
    "#  1.2.1 select and check all the ballots where country = test\n",
    "dropped_test_teams_df = df[df['country'] == 'test'][['country', 'Team Name']].copy()\n",
    "\n",
    "# 1.2.2 select and check all the ballots where country = 'Corporate'\n",
    "dropped_Corporate_teams_df = df[df['country'] == 'Corporate'][['country', 'Team Name']].copy()\n",
    "\n",
    "print(dropped_test_teams_df)\n",
    "dropped_test_teams_df.shape\n",
    "print(dropped_Corporate_teams_df)\n",
    "dropped_Corporate_teams_df.shape\n",
    "\n",
    "# 1.2.3      drop illigitimate ballots from test and corporate teams.\n",
    "df = df.drop(df[df.country == 'test'].index)\n",
    "df = df.drop(df[df.country == 'Corporate'].index)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fd277c-ed53-482f-8e64-a6d5502f72ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 1.3v : recoding answers from string to integer in order to compute scores and means\n",
    "# FOR VOLUNTEER DATA\n",
    "# 1.3.1v Replacing string values with integers to compute scores and means\n",
    "\n",
    "# Define the mapping of categorical values to integers\n",
    "mapping = {\n",
    "    'Strongly disagree': 1,\n",
    "    'Somewhat disagree': 2,\n",
    "    'Neutral': 3,\n",
    "    'Somewhat agree': 4,\n",
    "    'Strongly agree': 5\n",
    "}\n",
    "\n",
    "# For the 24 first columns, transform the categorical column into integers using the mapping\n",
    "\n",
    "for col in df.columns[:24]:\n",
    "    df[col] = df[col].replace(mapping)\n",
    "\n",
    "#replace string values with real numbers 1-7 to compute means for frequency variable, by teams\n",
    "# At my volunteer activity, I feel strong and vigorous      column[24].      --> positive outcome = 7 so reverse order\n",
    "# I feel emotionally drained from my work. column[25]      ---> positive outcome = 1\n",
    "# I feel frustrated by my work.            column[26]      ---> positive outcome = 1\n",
    "\n",
    "# for volunteers: 1=\"every time\" and for staff: 1=\"every day\" - correct mapping below accordingly.\n",
    "\n",
    "# At work, I feel strong and vigorous      column[24].      --> positive outcome = 7 so reverse order\n",
    "\n",
    "mapping = {\n",
    "    \"Every time\": 7,\n",
    "    \"Very often\": 6,\n",
    "    \"Often\": 5,\n",
    "    \"Sometimes\": 4,\n",
    "    \"Rarely\": 3,\n",
    "    \"Almost never\": 2,\n",
    "    \"Never\": 1\n",
    "} \n",
    "\n",
    "df['At my volunteer activity, I feel strong and vigorous.'] = df['At my volunteer activity, I feel strong and vigorous.'].replace(mapping)\n",
    "\n",
    "# 'I feel emotionally drained from my volunteer activity.\n",
    "# 'I feel frustrated by my volunteer activity.\n",
    "#mapping = {\n",
    "#    \"Every time\": 1,\n",
    "#    \"Very often\": 2,\n",
    "#    \"Often\": 3,\n",
    "#    \"Sometimes\": 4,\n",
    "#    \"Rarely\": 5,\n",
    "#    \"Almost never\": 6,\n",
    "#    \"Never\": 7\n",
    "#}\n",
    "\n",
    "df['I feel emotionally drained from my volunteer activity.'] = df['I feel emotionally drained from my volunteer activity.'].replace(mapping)\n",
    "df['I feel frustrated by my volunteer activity.'] = df['I feel frustrated by my volunteer activity.'].replace(mapping)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ecd273-2805-456a-bc3c-03fc2378a3cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 1.3s : recoding answers from string to integer in order to compute scores and means\n",
    "# FOR STAFF DATA\n",
    "# 1.3.1s Replacing string values with integers to compute scores and means\n",
    "\n",
    "# Define the mapping of categorical values to integers\n",
    "mapping = {\n",
    "    'Strongly disagree': 1,\n",
    "    'Somewhat disagree': 2,\n",
    "    'Neutral': 3,\n",
    "    'Somewhat agree': 4,\n",
    "    'Strongly agree': 5\n",
    "}\n",
    "\n",
    "# For the 24 first columns, transform the categorical column into integers using the mapping\n",
    "\n",
    "for col in df.columns[:24]:\n",
    "    df[col] = df[col].replace(mapping)\n",
    "\n",
    "#replace string values with real numbers 1-7 to compute means for frequency variable, by teams\n",
    "# At work, I feel strong and vigorous      column[24].      --> positive outcome = 7 so reverse order\n",
    "# I feel emotionally drained from my work. column[25]      ---> positive outcome = 1\n",
    "# I feel frustrated by my work.            column[26]      ---> positive outcome = 1\n",
    "\n",
    "# for volunteers: 1=\"every time\" and for staff: 1=\"every day\" - correct mapping below accordingly.\n",
    "\n",
    "# At work, I feel strong and vigorous      column[24].      --> positive outcome = 7 so reverse order\n",
    "\n",
    "mapping = {\n",
    "    \"Every day\": 7,\n",
    "    \"Very often\": 6,\n",
    "    \"Often\": 5,\n",
    "    \"Sometimes\": 4,\n",
    "    \"Rarely\": 3,\n",
    "    \"Almost never\": 2,\n",
    "    \"Never\": 1\n",
    "}\n",
    "\n",
    "df['At work, I feel strong and vigorous.'] = df['At work, I feel strong and vigorous.'].replace(mapping)\n",
    "df['I feel emotionally drained from my work.'] = df['I feel emotionally drained from my work.'].replace(mapping)\n",
    "df['I feel frustrated by my work.'] = df['I feel frustrated by my work.'].replace(mapping)\n",
    "\n",
    "# I feel emotionally drained from my work.\n",
    "# I feel frustrated by my work.\n",
    "#mapping = {\n",
    "#    \"Every day\": 1,\n",
    "#    \"Very often\": 2,\n",
    "#    \"Often\": 3,\n",
    "#    \"Sometimes\": 4,\n",
    "#    \"Rarely\": 5,\n",
    "#    \"Almost never\": 6,\n",
    "#    \"Never\": 7\n",
    "#}\n",
    "\n",
    "#df['I feel emotionally drained from my work.'] = df['I feel emotionally drained from my work.'].replace(mapping)\n",
    "#df['I feel frustrated by my work.'] = df['I feel frustrated by my work.'].replace(mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc914df8-5198-487d-b636-e6984c7be831",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FOR VOLUNTEER DATA\n",
    "# 1.3.2v We now create the scores for each dimension, e.g. autonomy, belonging, etc.\n",
    "# NB: Change questions for staff data\n",
    "\n",
    "#  Before computing the well-being score \n",
    "#  we need to recode the two following columns so that the positive outcomes get the higher scores\n",
    "# 'I feel emotionally drained from my volunteer activity.\n",
    "# 'I feel frustrated by my volunteer activity.\n",
    "\n",
    "mapping = {\n",
    "    7: 1,\n",
    "    6: 2,\n",
    "    5: 3,\n",
    "    4: 4,\n",
    "    3: 5,\n",
    "    2: 6,\n",
    "    1: 7\n",
    "}\n",
    "\n",
    "df['I feel emotionally drained from my volunteer activity.'] = df['I feel emotionally drained from my volunteer activity.'].replace(mapping)\n",
    "df['I feel frustrated by my volunteer activity.'] = df['I feel frustrated by my volunteer activity.'].replace(mapping)\n",
    "\n",
    "# Specify the column names for Well-being\n",
    "column_names = [\n",
    "    'At my volunteer activity, I feel strong and vigorous.',\n",
    "    'I feel emotionally drained from my volunteer activity.',\n",
    "    'I feel frustrated by my volunteer activity.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Well-being'\n",
    "df['Well-being'] = df[column_names].mean(axis=1)\n",
    "\n",
    "# Rescale the 'Well-being' values from a range of 1-7 to 1-5 and runds the result\n",
    "df['Well-being'] = (df['Well-being'] - 1) * (4 / 6) + 1\n",
    "df['Well-being'] = df['Well-being'].round(1)\n",
    "\n",
    "## recode back to original values for the two \"negative\" variables\n",
    "#  after computing the well-being score for \"logical\" correlation analysis\n",
    "#  we need to recode the two following columns so that the negative outcomes get the higher scores\n",
    "# 'I feel emotionally drained from my volunteer activity.\n",
    "# 'I feel frustrated by my volunteer activity.\n",
    "\n",
    "mapping = {\n",
    "    7: 1,\n",
    "    6: 2,\n",
    "    5: 3,\n",
    "    4: 4,\n",
    "    3: 5,\n",
    "    2: 6,\n",
    "    1: 7\n",
    "}\n",
    "\n",
    "df['I feel emotionally drained from my volunteer activity.'] = df['I feel emotionally drained from my volunteer activity.'].replace(mapping)\n",
    "df['I feel frustrated by my volunteer activity.'] = df['I feel frustrated by my volunteer activity.'].replace(mapping)\n",
    "\n",
    "\n",
    "\n",
    "# Specify the column names for Engagement\n",
    "column_names = [\n",
    "    'If I could choose, I will be volunteering one year from now.',\n",
    "    'The team has a great deal of personal meaning for me.',\n",
    "    'Considering everything, I am satisfied with my volunteer activity.',\n",
    "    'I share my ideas with others to improve the team.',\n",
    "    'The things that I value in life are very similar to the things that the team values.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Engagement'\n",
    "df['Engagement'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for Autonomy\n",
    "column_names = [\n",
    "    'I feel like I can be myself at my volunteer activity.',\n",
    "    'The tasks I must do at my volunteer activity are in line with what I really want to do.',\n",
    "    'I am free to express my ideas and opinions on the volunteer activity.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Autonomy'\n",
    "df['Autonomy'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for belonging\n",
    "column_names = [\n",
    "    'At my volunteer activity, I feel part of a group.',\n",
    "    'At my volunteer activity, I can talk with people about things that really matter to me.',\n",
    "    'People at my volunteer activity care about me.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Belonging'\n",
    "df['Belonging'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for Competence\n",
    "column_names = [\n",
    "    'I really master my tasks at my volunteer activity.',\n",
    "    'I feel competent at my volunteer activity.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Competence'\n",
    "df['Competence'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "\n",
    "\n",
    "# Specify the column names for Needs\n",
    "column_names = [\n",
    "    'I feel like I can be myself at my volunteer activity.',\n",
    "    'The tasks I must do at my volunteer activity are in line with what I really want to do.',\n",
    "    'I am free to express my ideas and opinions on the volunteer activity.',\n",
    "    'At my volunteer activity, I feel part of a group.',\n",
    "    'At my volunteer activity, I can talk with people about things that really matter to me.',\n",
    "    'People at my volunteer activity care about me.',\n",
    "    'I really master my tasks at my volunteer activity.',\n",
    "    'I feel competent at my volunteer activity.'\n",
    "]\n",
    "\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Needs'\n",
    "df['Needs'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "\n",
    "# Specify the column names for Leadership\n",
    "column_names = [\n",
    "    'My supervisor listens to how I would like to do things.',\n",
    "    'I feel understood by my supervisor.',\n",
    "    'My supervisor encourages me to ask questions.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Leadership'\n",
    "df['Leadership'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "\n",
    "# Specify the column names for 'Management'\n",
    "column_names = [\n",
    "    'I have the opportunity to develop my social network in my volunteer activity.',\n",
    "    'I have been able to learn interesting new skills on my volunteer activity.',\n",
    "    'I am fairly rewarded considering the responsibilities I have.',\n",
    "    'I am fairly rewarded for the work I do well.',\n",
    "    'My family, friends and my neighborhood appreciate the work I do for the team.',\n",
    "    'I feel my work has positive impact on other people.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Management'\n",
    "df['Management'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for 'Returns'\n",
    "column_names = [\n",
    "    'I have the opportunity to develop my social network in my volunteer activity.',\n",
    "    'I have been able to learn interesting new skills on my volunteer activity.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Returns'\n",
    "df['Returns'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for 'Rewards'\n",
    "column_names = [\n",
    "    'I am fairly rewarded considering the responsibilities I have.',\n",
    "    'I am fairly rewarded for the work I do well.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Rewards'\n",
    "df['Rewards'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for 'Status'\n",
    "column_names = [\n",
    "    'My family, friends and my neighborhood appreciate the work I do for the team.',\n",
    "    'I feel my work has positive impact on other people.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Status'\n",
    "df['Status'] = df[column_names].mean(axis=1).round(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dc09ddd-b003-4c59-907b-3b4764a59e3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FOR STAFF DATA\n",
    "# # 1.3.2s We now create the scores for each dimension, e.g. autonomy, belonging, etc.\n",
    "# NB: Change questions for staff data\n",
    "\n",
    "#  Before computing the well-being score \n",
    "#  we need to recode the two following columns so that the positive outcomes get the higher scores\n",
    "# 'I feel emotionally drained from my volunteer activity.\n",
    "# 'I feel frustrated by my volunteer activity.\n",
    "\n",
    "mapping = {\n",
    "    7: 1,\n",
    "    6: 2,\n",
    "    5: 3,\n",
    "    4: 4,\n",
    "    3: 5,\n",
    "    2: 6,\n",
    "    1: 7\n",
    "}\n",
    "\n",
    "df['I feel emotionally drained from my work.'] = df['I feel emotionally drained from my work.'].replace(mapping)\n",
    "df['I feel frustrated by my work.'] = df['I feel frustrated by my work.'].replace(mapping)\n",
    "\n",
    "# Specify the column names for Well-being\n",
    "column_names = [\n",
    "    'At work, I feel strong and vigorous.',\n",
    "    'I feel emotionally drained from my work.',\n",
    "    'I feel frustrated by my work.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Well-being'\n",
    "df['Well-being'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Rescale the 'Well-being' values from a range of 1-7 to 1-5 and runds the result\n",
    "df['Well-being'] = (df['Well-being'] - 1) * (4 / 6) + 1\n",
    "df['Well-being'] = df['Well-being'].round(1)\n",
    "\n",
    "## recode back to riginal values for the two \"negative\" variables\n",
    "#  after computing the well-being score for \"logical\" correlation analysis\n",
    "#  we need to recode the two following columns so that the negative outcomes get the higher scores\n",
    "# 'I feel emotionally drained from my work.\n",
    "# 'I feel frustrated by my work.\n",
    "\n",
    "mapping = {\n",
    "    7: 1,\n",
    "    6: 2,\n",
    "    5: 3,\n",
    "    4: 4,\n",
    "    3: 5,\n",
    "    2: 6,\n",
    "    1: 7\n",
    "}\n",
    "\n",
    "df['I feel emotionally drained from my work.'] = df['I feel emotionally drained from my work.'].replace(mapping)\n",
    "df['I feel frustrated by my work.'] = df['I feel frustrated by my work.'].replace(mapping)\n",
    "\n",
    "\n",
    "# Specify the column names for Engagement\n",
    "column_names = [\n",
    "    'If I could choose, I would continue working in my team one year from now.',\n",
    "    'The team means a lot to me personally.',\n",
    "    'Considering everything, I am satisfied with my work.',\n",
    "    'I share my ideas with others to improve the team.',\n",
    "    'The things that I value in life are very similar to the things that the team values.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Engagement'\n",
    "df['Engagement'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for Autonomy\n",
    "column_names = [\n",
    "    'I feel like I can be myself at work.',\n",
    "    'My tasks at my work are in line with what I really want to do.',\n",
    "    'I am free to express my ideas and opinions on my work.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Autonomy'\n",
    "df['Autonomy'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for belonging\n",
    "column_names = [\n",
    "    'At my work, I feel part of a group.',\n",
    "    'At my work, I can talk with people about things that really matter to me.',\n",
    "    'People at my work care about me.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Belonging'\n",
    "df['Belonging'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for Competence\n",
    "column_names = [\n",
    "    'I really master my tasks at work.',\n",
    "    'I feel competent at work.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Competence'\n",
    "df['Competence'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "\n",
    "# Specify the column names for Needs\n",
    "column_names = [\n",
    "    'I feel like I can be myself at work.',\n",
    "    'My tasks at my work are in line with what I really want to do.',\n",
    "    'I am free to express my ideas and opinions on my work.',\n",
    "    'At my work, I feel part of a group.',\n",
    "    'At my work, I can talk with people about things that really matter to me.',\n",
    "    'People at my work care about me.',\n",
    "    'I really master my tasks at work.',\n",
    "    'I feel competent at work.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Needs'\n",
    "df['Needs'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "\n",
    "\n",
    "# Specify the column names for Leadership\n",
    "column_names = [\n",
    "    'My supervisor listens to how I would like to do things.',\n",
    "    'I feel understood by my supervisor.',\n",
    "    'My supervisor encourages me to ask questions.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Leadership'\n",
    "df['Leadership'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for 'Management'\n",
    "column_names = [\n",
    "    'I have the opportunity to develop my social network at work.',\n",
    "    'I have been able to learn interesting new skills at work.',\n",
    "    'I am fairly rewarded considering the responsibilities I have.',\n",
    "    'I am fairly rewarded for the work I do well.',\n",
    "    'My family and friends appreciate the work I do for the team.',\n",
    "    'I feel my work has positive impact on other people.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Management'\n",
    "df['Management'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for 'Returns'\n",
    "column_names = [\n",
    "    'I have the opportunity to develop my social network at work.',\n",
    "    'I have been able to learn interesting new skills at work.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Returns'\n",
    "df['Returns'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for 'Rewards'\n",
    "column_names = [\n",
    "    'I am fairly rewarded considering the responsibilities I have.',\n",
    "    'I am fairly rewarded for the work I do well.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Rewards'\n",
    "df['Rewards'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for 'Status'\n",
    "column_names = [\n",
    "    'My family and friends appreciate the work I do for the team.',\n",
    "    'I feel my work has positive impact on other people.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Status'\n",
    "df['Status'] = df[column_names].mean(axis=1).round(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea64cac6-35ff-4f55-8202-52e13f74ac34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 1.4   VOLUNTEERS AND STAFF\n",
    "# Rename columns in their abridged form to allow VOL-STAFF df concatenation\n",
    "cols_to_update = [\n",
    "    'Myself',\n",
    "    'Tasks',\n",
    "    'Free',\n",
    "    'Mastery',\n",
    "    'Competent',\n",
    "    'Learn',\n",
    "    'Group',\n",
    "    'Talk',\n",
    "    'Care',\n",
    "    'Satisfied',\n",
    "    'Meaning',\n",
    "    'Stay',\n",
    "    'Ideas',\n",
    "    'Values',\n",
    "    'Understands',\n",
    "    'Encourages',\n",
    "    'Listens',\n",
    "    'Network',\n",
    "    'Friendly',\n",
    "    'Team',\n",
    "    'Appreciated',\n",
    "    'Responsibilities',\n",
    "    'Work',\n",
    "    'Impact',\n",
    "    'Strong',\n",
    "    'Drained',\n",
    "    'Frustrated'\n",
    "    ] + df.columns[27:].tolist()\n",
    "\n",
    "df.columns = cols_to_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e784768-2dfa-4b2f-9504-9998862df6f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa021baa-beb5-477f-b6fe-30de6fb108f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 1.5v FOR VOLUNTEERS\n",
    "# Export VOLUNTEER dataframe with composite indicators before grouping by teams\n",
    "ungrouped_df = df\n",
    "#ungrouped_df.to_excel('ungrouped_volunteers.xlsx', index=False)\n",
    "ungrouped_df.to_csv('ungrouped_volunteers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "702d9e9a-f788-4a65-9ad2-9f8394155524",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 1.5s FOR STAFF\n",
    "# Export STAFF dataframe with composite indicators before grouping by teams\n",
    "#from openpyxl import Workbook\n",
    "#wb.save(\"sample.xlsx\")\n",
    "ungrouped_df = df\n",
    "#ungrouped_df.to_excel('ungrouped_staff.xlsx', index=False)\n",
    "ungrouped_df.to_csv('ungrouped_staff.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c904d717-6cc0-4195-9a65-89e499fbb619",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 2  -  Create one data frame with all ungrouped data with abridged column names:\n",
    "# Here we merge the two team summary tables, one for Staff / Volunteer comparisons\n",
    "\n",
    "# Define the columns to include in the merged dataframe\n",
    "columns = ['Team Name', 'country', 'Well-being', 'Needs', 'Engagement', 'Autonomy', 'Belonging',\n",
    "           'Competence', 'Leadership', 'Management', 'Returns',\n",
    "           'Rewards', 'Status',\n",
    "    'Myself',\n",
    "    'Tasks',\n",
    "    'Free',\n",
    "    'Mastery',\n",
    "    'Competent',\n",
    "    'Learn',\n",
    "    'Group',\n",
    "    'Talk',\n",
    "    'Care',\n",
    "    'Satisfied',\n",
    "    'Meaning',\n",
    "    'Stay',\n",
    "    'Ideas',\n",
    "    'Values',\n",
    "    'Understands',\n",
    "    'Encourages',\n",
    "    'Listens',\n",
    "    'Network',\n",
    "    'Friendly',\n",
    "    'Team',\n",
    "    'Appreciated',\n",
    "    'Responsibilities',\n",
    "    'Work',\n",
    "    'Impact',\n",
    "    'Strong',\n",
    "    'Drained',\n",
    "    'Frustrated']\n",
    "\n",
    "# Read VOLUNTEER dataframe\n",
    "df_VOL = pd.read_csv(\"C:/Users/gabriel.pictet/Documents/Gabriel/REAL/Moti/Moti data/ungrouped_volunteers.csv\")\n",
    "\n",
    "# Create the table with the desired columns\n",
    "df_VOL = df_VOL[columns]\n",
    "\n",
    "# Round the values to one decimal point\n",
    "df_VOL = df_VOL.round(decimals=1)\n",
    "\n",
    "# Create a Volunteer dummy variable where Volunteer = 1\n",
    "df_VOL['Volunteer'] = 1\n",
    "df_VOL['Staff'] = 0\n",
    "df_VOL['Position'] = 'Volunteer'\n",
    "\n",
    "# Read STAFF dataframe\n",
    "df_STAFF = pd.read_csv(\"C:/Users/gabriel.pictet/Documents/Gabriel/REAL/Moti/Moti data/ungrouped_staff.csv\")\n",
    "\n",
    "# Create the table with the desired columns\n",
    "df_STAFF = df_STAFF[columns]\n",
    "\n",
    "# Round the values to one decimal point\n",
    "df_STAFF = df_STAFF.round(decimals=1)\n",
    "\n",
    "# Create a Staff dummy variable where Staff = 1\n",
    "df_STAFF['Volunteer'] = 0\n",
    "df_STAFF['Staff'] = 1\n",
    "df_STAFF['Position'] = 'Staff'\n",
    "\n",
    "# Merge the two dataframes\n",
    "df_VOLandSTAFF = pd.concat([df_VOL, df_STAFF], ignore_index=True)\n",
    "\n",
    "df_VOLandSTAFF.shape\n",
    "#df_VOLandSTAFF.to_excel('ungrouped_ALL.xlsx', index=False)\n",
    "df_VOLandSTAFF.to_csv('ungrouped_ALL.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d614b44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3\n",
    "# STEP 1.1 Create country variable based on Team Name\n",
    "# Assigns a country to each team\n",
    "# Prompts user to allocate country to new teams\n",
    "# and updates country_team_dictionary Runs allocation\n",
    "\n",
    "\n",
    "with open(\"team_country_allocation.py\") as file:\n",
    "    exec(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3404e4-0e15-449a-a7e3-12bde8e79ff0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 3: country tables, one for volunteers, one for staff and one for all.\n",
    "# STEP 3.ALL: country tables, all respondents, volunteers and staff alike.\n",
    "\n",
    "# 3.1.ALL Group rows by 'Country' and calculate size (count) for each group\n",
    "df = pd.read_csv(\"C:/Users/gabriel.pictet/Documents/Gabriel/REAL/Moti/Moti data/ungrouped_ALL.csv\")\n",
    "\n",
    "## for ALL, i.e. no more distinctions between volunteers and staff\n",
    "country_df = df.groupby('country').size().reset_index(name='size (n)')\n",
    "\n",
    "# 3.2.ALL Calculate the mean and median for each column\n",
    "mean_df = df.groupby('country').mean().reset_index()\n",
    "median_df = df.groupby('country').median().reset_index()\n",
    "\n",
    "# 3.3.ALL Count unique occurrences of 'Team Name' for each country\n",
    "n_teams_df = df.groupby('country')['Team Name'].nunique().reset_index(name='nTeams')\n",
    "\n",
    "# 3.4.ALL Merge the size (count), mean, median, and nTeams DataFrames\n",
    "country_df = country_df.merge(n_teams_df, on='country').merge(mean_df, on='country', suffixes=('_mean', '_median')).merge(median_df, on='country', suffixes=('_mean', '_median'))\n",
    "\n",
    "country_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e1eb39-715f-4782-bee0-b545afc8159b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 3.5.ALL  Identify, and check illigitamate survey ballots where team size smaller than 4\n",
    "# there is a logic issue here - we cannot get rid of teams < 4 after groupby country.\n",
    "# if we groupby country from the teamsALL dataset then the means and averages will be wrong...\n",
    "\n",
    "df = country_df\n",
    "\n",
    "# How many small teams are we talking about?\n",
    "dropped_small_teams_df = df[df['size (n)'] < 4][['country', 'size (n)']].copy()\n",
    "print(dropped_small_teams_df)\n",
    "dropped_small_teams_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1df5084-1ab5-44ca-871f-7c78b09563db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 3.6.ALL  Drop from illigitamate teams from country dataset\n",
    "df = df.drop(df[df['size (n)'] < 4].index)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8bee75b-d625-4e54-83de-9b68d8cc23e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3.7.ALL  Export country-level aggregations to Excel\n",
    "#country_df.to_excel('country_ALL.xlsx', index=False)\n",
    "country_df.to_csv('country_ALL.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01d53841-4ac7-46e8-baf6-e1bdb8723571",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      country  size (n)\n",
      "8      Global         2\n",
      "11  Indonesia         1\n",
      "18     Serbia         1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabriel.pictet\\AppData\\Local\\Temp\\ipykernel_21140\\3162689540.py:13: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  mean_df = df.groupby('country').mean().reset_index()\n",
      "C:\\Users\\gabriel.pictet\\AppData\\Local\\Temp\\ipykernel_21140\\3162689540.py:14: FutureWarning: The default value of numeric_only in DataFrameGroupBy.median is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  median_df = df.groupby('country').median().reset_index()\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: country tables, one for volunteers, one for staff and one for all.\n",
    "# STEP 3.VOL: country tables volunteers only\n",
    "\n",
    "# 3.1.VOL Group rows by 'Country' and calculate size (count) for each group\n",
    "df = pd.read_csv(\"C:/Users/gabriel.pictet/Documents/Gabriel/REAL/Moti/Moti data/ungrouped_ALL.csv\")\n",
    "\n",
    "## for VOL, i.e.  volunteers only\n",
    "# Filter the dataframe for 'Position' = 'Volunteer'\n",
    "df = df[df['Position'] == 'Volunteer']\n",
    "country_df = df.groupby('country').size().reset_index(name='size (n)')\n",
    "\n",
    "# 3.2.VOL Calculate the mean and median for each column\n",
    "mean_df = df.groupby('country').mean().reset_index()\n",
    "median_df = df.groupby('country').median().reset_index()\n",
    "\n",
    "# 3.3.VOL Count unique occurrences of 'Team Name' for each country\n",
    "n_teams_df = df.groupby('country')['Team Name'].nunique().reset_index(name='nTeams')\n",
    "\n",
    "# 3.4.ALL Merge the size (count), mean, median, and nTeams DataFrames\n",
    "country_df = country_df.merge(n_teams_df, on='country').merge(mean_df, on='country', suffixes=('_mean', '_median')).merge(median_df, on='country', suffixes=('_mean', '_median'))\n",
    "\n",
    "country_df.shape\n",
    "\n",
    "# STEP 3.5.VOL  Identify, and check illigitamate survey ballots where team size smaller than 4\n",
    "# there is a logic issue here - we cannot get rid of teams < 4 after groupby country.\n",
    "# if we groupby country from the teamsALL dataset then the means and averages will be wrong...\n",
    "\n",
    "df = country_df\n",
    "\n",
    "# How many small teams are we talking about?\n",
    "dropped_small_teams_df = df[df['size (n)'] < 4][['country', 'size (n)']].copy()\n",
    "print(dropped_small_teams_df)\n",
    "dropped_small_teams_df.shape\n",
    "\n",
    "# STEP 3.6.VOL  Drop from illigitamate teams from country dataset\n",
    "df = df.drop(df[df['size (n)'] < 4].index)\n",
    "df.shape\n",
    "\n",
    "# STEP 3.7.VOL  Export country-level aggregations to Excel\n",
    "country_df.to_excel('country_VOL.xlsx', index=False)\n",
    "country_df.to_csv('country_VOL.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a147e4e5-2afc-4f5a-9e5d-1a2cbe5a7b50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [country, size (n)]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabriel.pictet\\AppData\\Local\\Temp\\ipykernel_21140\\2991092071.py:12: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  mean_df = df.groupby('country').mean().reset_index()\n",
      "C:\\Users\\gabriel.pictet\\AppData\\Local\\Temp\\ipykernel_21140\\2991092071.py:13: FutureWarning: The default value of numeric_only in DataFrameGroupBy.median is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  median_df = df.groupby('country').median().reset_index()\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: country tables, one for volunteers, one for staff and one for all.\n",
    "# STEP 3.STAFF: country tables staff only\n",
    "\n",
    "# 3.1.STAFF Group rows by 'Country' and calculate size (count) for each group\n",
    "df = pd.read_csv(\"C:/Users/gabriel.pictet/Documents/Gabriel/REAL/Moti/Moti data/ungrouped_ALL.csv\")\n",
    "\n",
    "# Filter the dataframe for 'Position' = 'Staff'\n",
    "df = df[df['Position'] == 'Staff']\n",
    "country_df = df.groupby('country').size().reset_index(name='size (n)')\n",
    "\n",
    "# 3.2.STAFF Calculate the mean and median for each column\n",
    "mean_df = df.groupby('country').mean().reset_index()\n",
    "median_df = df.groupby('country').median().reset_index()\n",
    "\n",
    "# 3.3.VOL Count unique occurrences of 'Team Name' for each country\n",
    "n_teams_df = df.groupby('country')['Team Name'].nunique().reset_index(name='nTeams')\n",
    "\n",
    "# 3.4.ALL Merge the size (count), mean, median, and nTeams DataFrames\n",
    "country_df = country_df.merge(n_teams_df, on='country').merge(mean_df, on='country', suffixes=('_mean', '_median')).merge(median_df, on='country', suffixes=('_mean', '_median'))\n",
    "\n",
    "country_df.shape\n",
    "\n",
    "# STEP 3.5.STAFF  Identify, and check illigitamate survey ballots where team size smaller than 4\n",
    "# there is a logic issue here - we cannot get rid of teams < 4 after groupby country.\n",
    "# if we groupby country from the teamsALL dataset then the means and averages will be wrong...\n",
    "\n",
    "df = country_df\n",
    "\n",
    "# How many small teams are we talking about?\n",
    "dropped_small_teams_df = df[df['size (n)'] < 4][['country', 'size (n)']].copy()\n",
    "print(dropped_small_teams_df)\n",
    "dropped_small_teams_df.shape\n",
    "\n",
    "# STEP 3.6.STAFF  Drop from illigitamate teams from country dataset\n",
    "df = df.drop(df[df['size (n)'] < 4].index)\n",
    "df.shape\n",
    "\n",
    "# STEP 3.7.STAFF  Export country-level aggregations to Excel\n",
    "country_df.to_excel('country_STAFF.xlsx', index=False)\n",
    "country_df.to_csv('country_STAFF.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6182a784-b6e1-4e27-8d3a-b9ee6b78d0b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "agg function failed [how->mean,dtype->object]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\anaconda3\\envs\\MotiSurveyData\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1942\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[1;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1941\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1942\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grouper\u001b[38;5;241m.\u001b[39magg_series(ser, alt, preserve_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\anaconda3\\envs\\MotiSurveyData\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:864\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[1;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[0;32m    862\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 864\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_series_pure_python(obj, func)\n\u001b[0;32m    866\u001b[0m npvalues \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\anaconda3\\envs\\MotiSurveyData\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:885\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[1;34m(self, obj, func)\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[1;32m--> 885\u001b[0m     res \u001b[38;5;241m=\u001b[39m func(group)\n\u001b[0;32m    886\u001b[0m     res \u001b[38;5;241m=\u001b[39m extract_result(res)\n",
      "File \u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\anaconda3\\envs\\MotiSurveyData\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2454\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   2451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2452\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   2453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m-> 2454\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[0;32m   2455\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   2456\u001b[0m     )\n\u001b[0;32m   2457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\anaconda3\\envs\\MotiSurveyData\\Lib\\site-packages\\pandas\\core\\series.py:6549\u001b[0m, in \u001b[0;36mSeries.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m   6541\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   6542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m   6543\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6547\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   6548\u001b[0m ):\n\u001b[1;32m-> 6549\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\anaconda3\\envs\\MotiSurveyData\\Lib\\site-packages\\pandas\\core\\generic.py:12420\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  12414\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  12415\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12418\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  12419\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 12420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  12421\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  12422\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\anaconda3\\envs\\MotiSurveyData\\Lib\\site-packages\\pandas\\core\\generic.py:12377\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12375\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 12377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[0;32m  12378\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[0;32m  12379\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\anaconda3\\envs\\MotiSurveyData\\Lib\\site-packages\\pandas\\core\\series.py:6457\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   6453\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   6454\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6456\u001b[0m     )\n\u001b[1;32m-> 6457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\anaconda3\\envs\\MotiSurveyData\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\anaconda3\\envs\\MotiSurveyData\\Lib\\site-packages\\pandas\\core\\nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n",
      "File \u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\anaconda3\\envs\\MotiSurveyData\\Lib\\site-packages\\pandas\\core\\nanops.py:720\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum)\n\u001b[1;32m--> 720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(the_sum)\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\anaconda3\\envs\\MotiSurveyData\\Lib\\site-packages\\pandas\\core\\nanops.py:1701\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1699\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1700\u001b[0m     \u001b[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[1;32m-> 1701\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert string \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not convert string 'MexicoMexicoMexicoMexicoMexicoMexicoMexicoMexicoMexicoMexicoMexicoMexicoMexicoMexicoMexicoMexico' to numeric",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m team_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeam Name\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;241m.\u001b[39mreset_index(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize (n)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# STEP 4.2  Calculate the mean and median for each column\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m mean_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeam Name\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#median_df = df.groupby('Team Name').median().reset_index()\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# STEP 4.3  Merge the size (count), mean and country DataFrames\u001b[39;00m\n\u001b[0;32m     12\u001b[0m team_df \u001b[38;5;241m=\u001b[39m team_df\u001b[38;5;241m.\u001b[39mmerge(mean_df, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeam Name\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmerge(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeam Name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcountry\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPosition\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdrop_duplicates(), on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeam Name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\anaconda3\\envs\\MotiSurveyData\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2452\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[1;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[0;32m   2445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(\n\u001b[0;32m   2446\u001b[0m         grouped_mean,\n\u001b[0;32m   2447\u001b[0m         executor\u001b[38;5;241m.\u001b[39mfloat_dtype_mapping,\n\u001b[0;32m   2448\u001b[0m         engine_kwargs,\n\u001b[0;32m   2449\u001b[0m         min_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2450\u001b[0m     )\n\u001b[0;32m   2451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2452\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   2453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2454\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[0;32m   2455\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   2456\u001b[0m     )\n\u001b[0;32m   2457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\anaconda3\\envs\\MotiSurveyData\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1998\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[1;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1996\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m-> 1998\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgrouped_reduce(array_func)\n\u001b[0;32m   1999\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[0;32m   2000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmax\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\anaconda3\\envs\\MotiSurveyData\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1469\u001b[0m, in \u001b[0;36mBlockManager.grouped_reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_object:\n\u001b[0;32m   1466\u001b[0m     \u001b[38;5;66;03m# split on object-dtype blocks bc some columns may raise\u001b[39;00m\n\u001b[0;32m   1467\u001b[0m     \u001b[38;5;66;03m#  while others do not.\u001b[39;00m\n\u001b[0;32m   1468\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sb \u001b[38;5;129;01min\u001b[39;00m blk\u001b[38;5;241m.\u001b[39m_split():\n\u001b[1;32m-> 1469\u001b[0m         applied \u001b[38;5;241m=\u001b[39m sb\u001b[38;5;241m.\u001b[39mapply(func)\n\u001b[0;32m   1470\u001b[0m         result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m   1471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\anaconda3\\envs\\MotiSurveyData\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:393\u001b[0m, in \u001b[0;36mBlock.apply\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    395\u001b[0m     result \u001b[38;5;241m=\u001b[39m maybe_coerce_values(result)\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\anaconda3\\envs\\MotiSurveyData\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1995\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1992\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m   1994\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m alt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1995\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1996\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\anaconda3\\envs\\MotiSurveyData\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1946\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[1;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1944\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magg function failed [how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mser\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1945\u001b[0m     \u001b[38;5;66;03m# preserve the kind of exception that raised\u001b[39;00m\n\u001b[1;32m-> 1946\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(err)(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ser\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m   1949\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m res_values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: agg function failed [how->mean,dtype->object]"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec040583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary saved to team_country_dictionary.txt\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ef4812cc-b953-4bc3-be9c-a80b2fdcdc8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 4: create dataframe where one row is one team\n",
    "\n",
    "# STEP 4.1 Group rows by 'Team Name' and calculate size (count) for each team\n",
    "df = pd.read_csv(\"C:/Users/gabriel.pictet/Documents/Gabriel/REAL/Moti/Moti data/ungrouped_ALL.csv\")\n",
    "team_df = df.groupby('Team Name').size().reset_index(name='size (n)')\n",
    "\n",
    "# STEP 4.2  Calculate the mean and median for each column\n",
    "#mean_df = df.groupby('Team Name').mean().reset_index()\n",
    "#median_df = df.groupby('Team Name').median().reset_index()\n",
    "\n",
    "# STEP 4.3  Merge the size (count), mean and country DataFrames\n",
    "#team_df = team_df.merge(mean_df, on='Team Name').merge(df[['Team Name', 'country', 'Position']].drop_duplicates(), on='Team Name')\n",
    "\n",
    "# STEP 4.3  Merge the size (count), mean, median, and country DataFrames\n",
    "#team_df = team_df.merge(mean_df, on='Team Name', suffixes=('_mean', '_median')).merge(median_df, on='Team Name', suffixes=('_mean', '_median')).merge(df[['Team Name', 'country', 'Position']].drop_duplicates(), on='Team Name')\n",
    "\n",
    "team_df.info()\n",
    "\n",
    "# STEP 4.4  \n",
    "# For ALL (Volunteers and staff) - create files with Teams data\n",
    "#team_df.to_excel('team_ALL.xlsx', index=False)\n",
    "team_df.to_csv('team_ALL_short.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4997148-a346-4651-b438-40267ff94dca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

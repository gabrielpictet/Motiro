{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a0ae26c-d722-4354-9f63-12aa10ae09ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9937a37-f270-405c-a095-c3d80bb2b196",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabriel.pictet\\AppData\\Local\\Temp\\ipykernel_21828\\3483443009.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].replace(mapping)\n",
      "C:\\Users\\gabriel.pictet\\AppData\\Local\\Temp\\ipykernel_21828\\3483443009.py:41: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['At my volunteer activity, I feel strong and vigorous.'] = df['At my volunteer activity, I feel strong and vigorous.'].replace(mapping)\n",
      "C:\\Users\\gabriel.pictet\\AppData\\Local\\Temp\\ipykernel_21828\\3483443009.py:42: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['I feel emotionally drained from my volunteer activity.'] = df['I feel emotionally drained from my volunteer activity.'].replace(mapping)\n",
      "C:\\Users\\gabriel.pictet\\AppData\\Local\\Temp\\ipykernel_21828\\3483443009.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['I feel frustrated by my volunteer activity.'] = df['I feel frustrated by my volunteer activity.'].replace(mapping)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9067 entries, 0 to 9066\n",
      "Data columns (total 42 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Myself                       9067 non-null   int64  \n",
      " 1   Tasks                        9067 non-null   int64  \n",
      " 2   Free                         9067 non-null   int64  \n",
      " 3   Mastery                      9067 non-null   int64  \n",
      " 4   Competent                    9067 non-null   int64  \n",
      " 5   Learn                        9067 non-null   int64  \n",
      " 6   Group                        9067 non-null   int64  \n",
      " 7   Talk                         9067 non-null   int64  \n",
      " 8   Care                         9067 non-null   int64  \n",
      " 9   Satisfied                    9067 non-null   int64  \n",
      " 10  Meaning                      9067 non-null   int64  \n",
      " 11  Stay                         9067 non-null   int64  \n",
      " 12  Ideas                        9067 non-null   int64  \n",
      " 13  Values                       9067 non-null   int64  \n",
      " 14  Understands                  9067 non-null   int64  \n",
      " 15  Encourages                   9067 non-null   int64  \n",
      " 16  Listens                      9067 non-null   int64  \n",
      " 17  Network                      9067 non-null   int64  \n",
      " 18  Friendly                     9067 non-null   int64  \n",
      " 19  Team                         9067 non-null   int64  \n",
      " 20  Appreciated                  9067 non-null   int64  \n",
      " 21  Responsibilities             9067 non-null   int64  \n",
      " 22  Work                         9067 non-null   int64  \n",
      " 23  Impact                       9067 non-null   int64  \n",
      " 24  Strong                       9067 non-null   int64  \n",
      " 25  Drained                      9067 non-null   int64  \n",
      " 26  Frustrated                   9067 non-null   int64  \n",
      " 27  What year were you born in?  0 non-null      float64\n",
      " 28  What is your gender?         0 non-null      float64\n",
      " 29  Team Name                    9067 non-null   object \n",
      " 30  Survey Data                  9067 non-null   object \n",
      " 31  Well-being                   9067 non-null   float64\n",
      " 32  Engagement                   9067 non-null   float64\n",
      " 33  Autonomy                     9067 non-null   float64\n",
      " 34  Belonging                    9067 non-null   float64\n",
      " 35  Competence                   9067 non-null   float64\n",
      " 36  Needs                        9067 non-null   float64\n",
      " 37  Leadership                   9067 non-null   float64\n",
      " 38  Management                   9067 non-null   float64\n",
      " 39  Returns                      9067 non-null   float64\n",
      " 40  Rewards                      9067 non-null   float64\n",
      " 41  Status                       9067 non-null   float64\n",
      "dtypes: float64(13), int64(27), object(2)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# VOLUNTEERS - step 1\n",
    "# Read the uploaded .txt file with an alternative encoding\n",
    "# The csv file is corrupted by MS Excel so it needs to be opened in notepad and saved as a .txt file\n",
    "file_path = 'C:/Users/gabriel.pictet/Documents/Gabriel/REAL/Moti/Moti data/answers-volunteers.txt'\n",
    "df = pd.read_csv(file_path, sep=\",\", encoding='utf-8')\n",
    "#alternative encoding not working: df = pd.read_csv(file_path, sep=\",\", encoding='cp1252')\n",
    "# Display the last rows of the dataframe to verify successful loading\n",
    "df.tail()\n",
    "\n",
    "# STEP 1.1v : recoding answers from string to integer in order to compute scores and means\n",
    "\n",
    "# Define the mapping of categorical values to integers\n",
    "mapping = {\n",
    "    'Strongly disagree': 1,\n",
    "    'Somewhat disagree': 2,\n",
    "    'Neutral': 3,\n",
    "    'Somewhat agree': 4,\n",
    "    'Strongly agree': 5\n",
    "}\n",
    "\n",
    "# For the 24 first columns, transform the categorical column into integers using the mapping\n",
    "\n",
    "for col in df.columns[:24]:\n",
    "    df[col] = df[col].replace(mapping)\n",
    "\n",
    "#replace string values with real numbers 1-7 to compute means for frequency variable, by teams\n",
    "# At my volunteer activity, I feel strong and vigorous      column[24]     \n",
    "# I feel emotionally drained from my work.                  column[25]     \n",
    "# I feel frustrated by my work.                             column[26]  \n",
    "\n",
    "mapping = {\n",
    "    \"Every time\": 7,\n",
    "    \"Very often\": 6,\n",
    "    \"Often\": 5,\n",
    "    \"Sometimes\": 4,\n",
    "    \"Rarely\": 3,\n",
    "    \"Almost never\": 2,\n",
    "    \"Never\": 1\n",
    "} \n",
    "\n",
    "df['At my volunteer activity, I feel strong and vigorous.'] = df['At my volunteer activity, I feel strong and vigorous.'].replace(mapping)\n",
    "df['I feel emotionally drained from my volunteer activity.'] = df['I feel emotionally drained from my volunteer activity.'].replace(mapping)\n",
    "df['I feel frustrated by my volunteer activity.'] = df['I feel frustrated by my volunteer activity.'].replace(mapping)\n",
    "\n",
    "df.head()\n",
    "# VOLUNTEERS\n",
    "# STEP 1.2v : Create the scores for each dimension, e.g. autonomy, belonging, etc.\n",
    "#  Before computing the well-being score: \n",
    "#  recode the two following columns so that the positive outcomes get the higher scores\n",
    "# 'I feel emotionally drained from my volunteer activity.\n",
    "# 'I feel frustrated by my volunteer activity.\n",
    "\n",
    "mapping = {\n",
    "    7: 1,\n",
    "    6: 2,\n",
    "    5: 3,\n",
    "    4: 4,\n",
    "    3: 5,\n",
    "    2: 6,\n",
    "    1: 7\n",
    "}\n",
    "\n",
    "df['I feel emotionally drained from my volunteer activity.'] = df['I feel emotionally drained from my volunteer activity.'].replace(mapping)\n",
    "df['I feel frustrated by my volunteer activity.'] = df['I feel frustrated by my volunteer activity.'].replace(mapping)\n",
    "\n",
    "# Specify the column names for Well-being\n",
    "column_names = [\n",
    "    'At my volunteer activity, I feel strong and vigorous.',\n",
    "    'I feel emotionally drained from my volunteer activity.',\n",
    "    'I feel frustrated by my volunteer activity.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Well-being'\n",
    "df['Well-being'] = df[column_names].mean(axis=1)\n",
    "\n",
    "# Rescale the 'Well-being' values from a range of 1-7 to 1-5 and runds the result\n",
    "df['Well-being'] = (df['Well-being'] - 1) * (4 / 6) + 1\n",
    "df['Well-being'] = df['Well-being'].round(1)\n",
    "\n",
    "## recode back to original values for the two \"negative\" variables\n",
    "#  after computing the well-being score for \"logical\" correlation analysis\n",
    "#  we need to recode the two following columns so that the negative outcomes get the higher scores\n",
    "# 'I feel emotionally drained from my volunteer activity.\n",
    "# 'I feel frustrated by my volunteer activity.\n",
    "\n",
    "mapping = {\n",
    "    7: 1,\n",
    "    6: 2,\n",
    "    5: 3,\n",
    "    4: 4,\n",
    "    3: 5,\n",
    "    2: 6,\n",
    "    1: 7\n",
    "}\n",
    "\n",
    "df['I feel emotionally drained from my volunteer activity.'] = df['I feel emotionally drained from my volunteer activity.'].replace(mapping)\n",
    "df['I feel frustrated by my volunteer activity.'] = df['I feel frustrated by my volunteer activity.'].replace(mapping)\n",
    "\n",
    "\n",
    "# Specify the column names for Engagement\n",
    "column_names = [\n",
    "    'If I could choose, I will be volunteering one year from now.',\n",
    "    'The team has a great deal of personal meaning for me.',\n",
    "    'Considering everything, I am satisfied with my volunteer activity.',\n",
    "    'I share my ideas with others to improve the team.',\n",
    "    'The things that I value in life are very similar to the things that the team values.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Engagement'\n",
    "df['Engagement'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for Autonomy\n",
    "column_names = [\n",
    "    'I feel like I can be myself at my volunteer activity.',\n",
    "    'The tasks I must do at my volunteer activity are in line with what I really want to do.',\n",
    "    'I am free to express my ideas and opinions on the volunteer activity.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Autonomy'\n",
    "df['Autonomy'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for belonging\n",
    "column_names = [\n",
    "    'At my volunteer activity, I feel part of a group.',\n",
    "    'At my volunteer activity, I can talk with people about things that really matter to me.',\n",
    "    'People at my volunteer activity care about me.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Belonging'\n",
    "df['Belonging'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for Competence\n",
    "column_names = [\n",
    "    'I really master my tasks at my volunteer activity.',\n",
    "    'I feel competent at my volunteer activity.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Competence'\n",
    "df['Competence'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for Needs\n",
    "column_names = [\n",
    "    'I feel like I can be myself at my volunteer activity.',\n",
    "    'The tasks I must do at my volunteer activity are in line with what I really want to do.',\n",
    "    'I am free to express my ideas and opinions on the volunteer activity.',\n",
    "    'At my volunteer activity, I feel part of a group.',\n",
    "    'At my volunteer activity, I can talk with people about things that really matter to me.',\n",
    "    'People at my volunteer activity care about me.',\n",
    "    'I really master my tasks at my volunteer activity.',\n",
    "    'I feel competent at my volunteer activity.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Needs'\n",
    "df['Needs'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for Leadership\n",
    "column_names = [\n",
    "    'My supervisor listens to how I would like to do things.',\n",
    "    'I feel understood by my supervisor.',\n",
    "    'My supervisor encourages me to ask questions.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Leadership'\n",
    "df['Leadership'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for 'Management'\n",
    "column_names = [\n",
    "    'I have the opportunity to develop my social network in my volunteer activity.',\n",
    "    'I have been able to learn interesting new skills on my volunteer activity.',\n",
    "    'I am fairly rewarded considering the responsibilities I have.',\n",
    "    'I am fairly rewarded for the work I do well.',\n",
    "    'My family, friends and my neighborhood appreciate the work I do for the team.',\n",
    "    'I feel my work has positive impact on other people.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Management'\n",
    "df['Management'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for 'Returns'\n",
    "column_names = [\n",
    "    'I have the opportunity to develop my social network in my volunteer activity.',\n",
    "    'I have been able to learn interesting new skills on my volunteer activity.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Returns'\n",
    "df['Returns'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for 'Rewards'\n",
    "column_names = [\n",
    "    'I am fairly rewarded considering the responsibilities I have.',\n",
    "    'I am fairly rewarded for the work I do well.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Rewards'\n",
    "df['Rewards'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for 'Status'\n",
    "column_names = [\n",
    "    'My family, friends and my neighborhood appreciate the work I do for the team.',\n",
    "    'I feel my work has positive impact on other people.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Status'\n",
    "df['Status'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "\n",
    "# STEP 1.3v : Rename columns in their abridged form to allow VOL-STAFF df concatenation\n",
    "cols_to_update = [\n",
    "    'Myself',\n",
    "    'Tasks',\n",
    "    'Free',\n",
    "    'Mastery',\n",
    "    'Competent',\n",
    "    'Learn',\n",
    "    'Group',\n",
    "    'Talk',\n",
    "    'Care',\n",
    "    'Satisfied',\n",
    "    'Meaning',\n",
    "    'Stay',\n",
    "    'Ideas',\n",
    "    'Values',\n",
    "    'Understands',\n",
    "    'Encourages',\n",
    "    'Listens',\n",
    "    'Network',\n",
    "    'Friendly',\n",
    "    'Team',\n",
    "    'Appreciated',\n",
    "    'Responsibilities',\n",
    "    'Work',\n",
    "    'Impact',\n",
    "    'Strong',\n",
    "    'Drained',\n",
    "    'Frustrated'\n",
    "    ] + df.columns[27:].tolist()\n",
    "\n",
    "df.columns = cols_to_update\n",
    "\n",
    "df.info()\n",
    "\n",
    "# STEP 1.4v : Export VOLUNTEER dataframe with composite indicators before grouping by teams\n",
    "ungrouped_df = df\n",
    "ungrouped_df.to_csv('ungrouped_volunteers.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4f104e3-a215-44de-a515-e2c411b9615b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1383 entries, 0 to 1382\n",
      "Data columns (total 42 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Myself                       1383 non-null   int64  \n",
      " 1   Tasks                        1383 non-null   int64  \n",
      " 2   Free                         1383 non-null   int64  \n",
      " 3   Mastery                      1383 non-null   int64  \n",
      " 4   Competent                    1383 non-null   int64  \n",
      " 5   Learn                        1383 non-null   int64  \n",
      " 6   Group                        1383 non-null   int64  \n",
      " 7   Talk                         1383 non-null   int64  \n",
      " 8   Care                         1383 non-null   int64  \n",
      " 9   Satisfied                    1383 non-null   int64  \n",
      " 10  Meaning                      1383 non-null   int64  \n",
      " 11  Stay                         1383 non-null   int64  \n",
      " 12  Ideas                        1383 non-null   int64  \n",
      " 13  Values                       1383 non-null   int64  \n",
      " 14  Understands                  1383 non-null   int64  \n",
      " 15  Encourages                   1383 non-null   int64  \n",
      " 16  Listens                      1383 non-null   int64  \n",
      " 17  Network                      1383 non-null   int64  \n",
      " 18  Friendly                     1383 non-null   int64  \n",
      " 19  Team                         1383 non-null   int64  \n",
      " 20  Appreciated                  1383 non-null   int64  \n",
      " 21  Responsibilities             1383 non-null   int64  \n",
      " 22  Work                         1383 non-null   int64  \n",
      " 23  Impact                       1383 non-null   int64  \n",
      " 24  Strong                       1383 non-null   int64  \n",
      " 25  Drained                      1383 non-null   int64  \n",
      " 26  Frustrated                   1383 non-null   int64  \n",
      " 27  What year were you born in?  0 non-null      float64\n",
      " 28  What is your gender?         0 non-null      float64\n",
      " 29  Team Name                    1383 non-null   object \n",
      " 30  Survey Data                  1383 non-null   object \n",
      " 31  Well-being                   1383 non-null   float64\n",
      " 32  Engagement                   1383 non-null   float64\n",
      " 33  Autonomy                     1383 non-null   float64\n",
      " 34  Belonging                    1383 non-null   float64\n",
      " 35  Competence                   1383 non-null   float64\n",
      " 36  Needs                        1383 non-null   float64\n",
      " 37  Leadership                   1383 non-null   float64\n",
      " 38  Management                   1383 non-null   float64\n",
      " 39  Returns                      1383 non-null   float64\n",
      " 40  Rewards                      1383 non-null   float64\n",
      " 41  Status                       1383 non-null   float64\n",
      "dtypes: float64(13), int64(27), object(2)\n",
      "memory usage: 453.9+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabriel.pictet\\AppData\\Local\\Temp\\ipykernel_21828\\2757185632.py:21: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].replace(mapping)\n",
      "C:\\Users\\gabriel.pictet\\AppData\\Local\\Temp\\ipykernel_21828\\2757185632.py:35: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['At work, I feel strong and vigorous.'] = df['At work, I feel strong and vigorous.'].replace(mapping)\n",
      "C:\\Users\\gabriel.pictet\\AppData\\Local\\Temp\\ipykernel_21828\\2757185632.py:36: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['I feel emotionally drained from my work.'] = df['I feel emotionally drained from my work.'].replace(mapping)\n",
      "C:\\Users\\gabriel.pictet\\AppData\\Local\\Temp\\ipykernel_21828\\2757185632.py:37: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['I feel frustrated by my work.'] = df['I feel frustrated by my work.'].replace(mapping)\n"
     ]
    }
   ],
   "source": [
    "# STAFF Step 1\n",
    "\n",
    "# Open the Raw Moti Data CSV file as sent by CE\n",
    "df = pd.read_csv(\"C:/Users/gabriel.pictet/Documents/Gabriel/REAL/Moti/Moti data/answers-staff.txt\", sep=\",\", encoding='utf-8')\n",
    "df.shape\n",
    "\n",
    "# STEP 1.1s : recode answers from string to integer in order to compute scores and means\n",
    "\n",
    "# Define the mapping of categorical values to integers\n",
    "mapping = {\n",
    "    'Strongly disagree': 1,\n",
    "    'Somewhat disagree': 2,\n",
    "    'Neutral': 3,\n",
    "    'Somewhat agree': 4,\n",
    "    'Strongly agree': 5\n",
    "}\n",
    "\n",
    "# For the 24 first columns, transform the categorical column into integers using the mapping\n",
    "\n",
    "for col in df.columns[:24]:\n",
    "    df[col] = df[col].replace(mapping)\n",
    "\n",
    "# replace string values with real numbers 1-7 for frequency variable, by teams\n",
    "\n",
    "mapping = {\n",
    "    \"Every day\": 7,\n",
    "    \"Very often\": 6,\n",
    "    \"Often\": 5,\n",
    "    \"Sometimes\": 4,\n",
    "    \"Rarely\": 3,\n",
    "    \"Almost never\": 2,\n",
    "    \"Never\": 1\n",
    "}\n",
    "\n",
    "df['At work, I feel strong and vigorous.'] = df['At work, I feel strong and vigorous.'].replace(mapping)\n",
    "df['I feel emotionally drained from my work.'] = df['I feel emotionally drained from my work.'].replace(mapping)\n",
    "df['I feel frustrated by my work.'] = df['I feel frustrated by my work.'].replace(mapping)\n",
    "\n",
    "\n",
    "# STEP 1.2s : Create the scores for each dimension, e.g. autonomy, belonging, etc.\n",
    "# NB: Change questions for staff data\n",
    "\n",
    "#  Before computing the well-being score \n",
    "#  we need to recode the two following columns so that the positive outcomes get the higher scores\n",
    "# 'I feel emotionally drained from my volunteer activity.\n",
    "# 'I feel frustrated by my volunteer activity.\n",
    "\n",
    "mapping = {\n",
    "    7: 1,\n",
    "    6: 2,\n",
    "    5: 3,\n",
    "    4: 4,\n",
    "    3: 5,\n",
    "    2: 6,\n",
    "    1: 7\n",
    "}\n",
    "\n",
    "df['I feel emotionally drained from my work.'] = df['I feel emotionally drained from my work.'].replace(mapping)\n",
    "df['I feel frustrated by my work.'] = df['I feel frustrated by my work.'].replace(mapping)\n",
    "\n",
    "# Specify the column names for Well-being\n",
    "column_names = [\n",
    "    'At work, I feel strong and vigorous.',\n",
    "    'I feel emotionally drained from my work.',\n",
    "    'I feel frustrated by my work.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Well-being'\n",
    "df['Well-being'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Rescale the 'Well-being' values from a range of 1-7 to 1-5 and runds the result\n",
    "df['Well-being'] = (df['Well-being'] - 1) * (4 / 6) + 1\n",
    "df['Well-being'] = df['Well-being'].round(1)\n",
    "\n",
    "## recode back to original values for the two \"negative\" variables\n",
    "#  after computing the well-being score for \"logical\" correlation analysis\n",
    "#  we need to recode the two following columns so that the negative outcomes get the higher scores\n",
    "# 'I feel emotionally drained from my work.\n",
    "# 'I feel frustrated by my work.\n",
    "\n",
    "mapping = {\n",
    "    7: 1,\n",
    "    6: 2,\n",
    "    5: 3,\n",
    "    4: 4,\n",
    "    3: 5,\n",
    "    2: 6,\n",
    "    1: 7\n",
    "}\n",
    "\n",
    "df['I feel emotionally drained from my work.'] = df['I feel emotionally drained from my work.'].replace(mapping)\n",
    "df['I feel frustrated by my work.'] = df['I feel frustrated by my work.'].replace(mapping)\n",
    "\n",
    "# Specify the column names for Engagement\n",
    "column_names = [\n",
    "    'If I could choose, I would continue working in my team one year from now.',\n",
    "    'The team means a lot to me personally.',\n",
    "    'Considering everything, I am satisfied with my work.',\n",
    "    'I share my ideas with others to improve the team.',\n",
    "    'The things that I value in life are very similar to the things that the team values.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Engagement'\n",
    "df['Engagement'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for Autonomy\n",
    "column_names = [\n",
    "    'I feel like I can be myself at work.',\n",
    "    'My tasks at my work are in line with what I really want to do.',\n",
    "    'I am free to express my ideas and opinions on my work.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Autonomy'\n",
    "df['Autonomy'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for belonging\n",
    "column_names = [\n",
    "    'At my work, I feel part of a group.',\n",
    "    'At my work, I can talk with people about things that really matter to me.',\n",
    "    'People at my work care about me.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Belonging'\n",
    "df['Belonging'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for Competence\n",
    "column_names = [\n",
    "    'I really master my tasks at work.',\n",
    "    'I feel competent at work.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Competence'\n",
    "df['Competence'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for Needs\n",
    "column_names = [\n",
    "    'I feel like I can be myself at work.',\n",
    "    'My tasks at my work are in line with what I really want to do.',\n",
    "    'I am free to express my ideas and opinions on my work.',\n",
    "    'At my work, I feel part of a group.',\n",
    "    'At my work, I can talk with people about things that really matter to me.',\n",
    "    'People at my work care about me.',\n",
    "    'I really master my tasks at work.',\n",
    "    'I feel competent at work.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Needs'\n",
    "df['Needs'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for Leadership\n",
    "column_names = [\n",
    "    'My supervisor listens to how I would like to do things.',\n",
    "    'I feel understood by my supervisor.',\n",
    "    'My supervisor encourages me to ask questions.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Leadership'\n",
    "df['Leadership'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for 'Management'\n",
    "column_names = [\n",
    "    'I have the opportunity to develop my social network at work.',\n",
    "    'I have been able to learn interesting new skills at work.',\n",
    "    'I am fairly rewarded considering the responsibilities I have.',\n",
    "    'I am fairly rewarded for the work I do well.',\n",
    "    'My family and friends appreciate the work I do for the team.',\n",
    "    'I feel my work has positive impact on other people.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Management'\n",
    "df['Management'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for 'Returns'\n",
    "column_names = [\n",
    "    'I have the opportunity to develop my social network at work.',\n",
    "    'I have been able to learn interesting new skills at work.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Returns'\n",
    "df['Returns'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for 'Rewards'\n",
    "column_names = [\n",
    "    'I am fairly rewarded considering the responsibilities I have.',\n",
    "    'I am fairly rewarded for the work I do well.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Rewards'\n",
    "df['Rewards'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for 'Status'\n",
    "column_names = [\n",
    "    'My family and friends appreciate the work I do for the team.',\n",
    "    'I feel my work has positive impact on other people.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Status'\n",
    "df['Status'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# STAFF   \n",
    "# STEP 1.3s : Rename columns in their abridged form to allow VOL-STAFF df concatenation\n",
    "cols_to_update = [\n",
    "    'Myself',\n",
    "    'Tasks',\n",
    "    'Free',\n",
    "    'Mastery',\n",
    "    'Competent',\n",
    "    'Learn',\n",
    "    'Group',\n",
    "    'Talk',\n",
    "    'Care',\n",
    "    'Satisfied',\n",
    "    'Meaning',\n",
    "    'Stay',\n",
    "    'Ideas',\n",
    "    'Values',\n",
    "    'Understands',\n",
    "    'Encourages',\n",
    "    'Listens',\n",
    "    'Network',\n",
    "    'Friendly',\n",
    "    'Team',\n",
    "    'Appreciated',\n",
    "    'Responsibilities',\n",
    "    'Work',\n",
    "    'Impact',\n",
    "    'Strong',\n",
    "    'Drained',\n",
    "    'Frustrated'\n",
    "    ] + df.columns[27:].tolist()\n",
    "\n",
    "df.columns = cols_to_update\n",
    "\n",
    "df.info()\n",
    "\n",
    "\n",
    "# STEP 1.4s : Export STAFF dataframe with composite indicators before grouping by teams\n",
    "ungrouped_df = df\n",
    "ungrouped_df.to_csv('ungrouped_staff.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c904d717-6cc0-4195-9a65-89e499fbb619",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10450 entries, 0 to 10449\n",
      "Data columns (total 43 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Team Name         10450 non-null  object \n",
      " 1   Survey Data       10450 non-null  object \n",
      " 2   Well-being        10450 non-null  float64\n",
      " 3   Needs             10450 non-null  float64\n",
      " 4   Engagement        10450 non-null  float64\n",
      " 5   Autonomy          10450 non-null  float64\n",
      " 6   Belonging         10450 non-null  float64\n",
      " 7   Competence        10450 non-null  float64\n",
      " 8   Leadership        10450 non-null  float64\n",
      " 9   Management        10450 non-null  float64\n",
      " 10  Returns           10450 non-null  float64\n",
      " 11  Rewards           10450 non-null  float64\n",
      " 12  Status            10450 non-null  float64\n",
      " 13  Myself            10450 non-null  int64  \n",
      " 14  Tasks             10450 non-null  int64  \n",
      " 15  Free              10450 non-null  int64  \n",
      " 16  Mastery           10450 non-null  int64  \n",
      " 17  Competent         10450 non-null  int64  \n",
      " 18  Learn             10450 non-null  int64  \n",
      " 19  Group             10450 non-null  int64  \n",
      " 20  Talk              10450 non-null  int64  \n",
      " 21  Care              10450 non-null  int64  \n",
      " 22  Satisfied         10450 non-null  int64  \n",
      " 23  Meaning           10450 non-null  int64  \n",
      " 24  Stay              10450 non-null  int64  \n",
      " 25  Ideas             10450 non-null  int64  \n",
      " 26  Values            10450 non-null  int64  \n",
      " 27  Understands       10450 non-null  int64  \n",
      " 28  Encourages        10450 non-null  int64  \n",
      " 29  Listens           10450 non-null  int64  \n",
      " 30  Network           10450 non-null  int64  \n",
      " 31  Friendly          10450 non-null  int64  \n",
      " 32  Team              10450 non-null  int64  \n",
      " 33  Appreciated       10450 non-null  int64  \n",
      " 34  Responsibilities  10450 non-null  int64  \n",
      " 35  Work              10450 non-null  int64  \n",
      " 36  Impact            10450 non-null  int64  \n",
      " 37  Strong            10450 non-null  int64  \n",
      " 38  Drained           10450 non-null  int64  \n",
      " 39  Frustrated        10450 non-null  int64  \n",
      " 40  Volunteer         10450 non-null  int64  \n",
      " 41  Staff             10450 non-null  int64  \n",
      " 42  Position          10450 non-null  object \n",
      "dtypes: float64(11), int64(29), object(3)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# STEP 2  -  MERGE into one data frame all ungrouped data with abridged column names\n",
    "\n",
    "# Define the columns to include in the merged dataframe\n",
    "columns = ['Team Name', 'Survey Data', 'Well-being', 'Needs', 'Engagement', 'Autonomy', 'Belonging',\n",
    "           'Competence', 'Leadership', 'Management', 'Returns',\n",
    "           'Rewards', 'Status',\n",
    "    'Myself',\n",
    "    'Tasks',\n",
    "    'Free',\n",
    "    'Mastery',\n",
    "    'Competent',\n",
    "    'Learn',\n",
    "    'Group',\n",
    "    'Talk',\n",
    "    'Care',\n",
    "    'Satisfied',\n",
    "    'Meaning',\n",
    "    'Stay',\n",
    "    'Ideas',\n",
    "    'Values',\n",
    "    'Understands',\n",
    "    'Encourages',\n",
    "    'Listens',\n",
    "    'Network',\n",
    "    'Friendly',\n",
    "    'Team',\n",
    "    'Appreciated',\n",
    "    'Responsibilities',\n",
    "    'Work',\n",
    "    'Impact',\n",
    "    'Strong',\n",
    "    'Drained',\n",
    "    'Frustrated']\n",
    "\n",
    "# Read VOLUNTEER dataframe\n",
    "df_VOL = pd.read_csv(\"ungrouped_volunteers.txt\", encoding='utf-8')\n",
    "\n",
    "# Create the table with the desired columns\n",
    "df_VOL = df_VOL[columns]\n",
    "\n",
    "# Round the values to one decimal point\n",
    "df_VOL = df_VOL.round(decimals=1)\n",
    "\n",
    "# Create a Volunteer dummy variable where Volunteer = 1\n",
    "df_VOL['Volunteer'] = 1\n",
    "df_VOL['Staff'] = 0\n",
    "df_VOL['Position'] = 'Volunteer'\n",
    "\n",
    "# Read STAFF dataframe\n",
    "df_STAFF = pd.read_csv(\"ungrouped_staff.txt\", encoding='utf-8')\n",
    "\n",
    "# Create the table with the desired columns\n",
    "df_STAFF = df_STAFF[columns]\n",
    "\n",
    "# Round the values to one decimal point\n",
    "df_STAFF = df_STAFF.round(decimals=1)\n",
    "\n",
    "# Create a Staff dummy variable where Staff = 1\n",
    "df_STAFF['Volunteer'] = 0\n",
    "df_STAFF['Staff'] = 1\n",
    "df_STAFF['Position'] = 'Staff'\n",
    "\n",
    "# Merge the two dataframes\n",
    "df_VOLandSTAFF = pd.concat([df_VOL, df_STAFF], ignore_index=True)\n",
    "\n",
    "df_VOLandSTAFF.shape\n",
    "#df_VOLandSTAFF.to_excel('ungrouped_ALL.xlsx', index=False)\n",
    "df_VOLandSTAFF.to_csv('ungrouped_ALL.txt', index=False)\n",
    "\n",
    "df_VOLandSTAFF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d614b44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataframe saved to Individual.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10331 entries, 0 to 10449\n",
      "Data columns (total 45 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Team Name         10331 non-null  object \n",
      " 1   Survey Data       10331 non-null  object \n",
      " 2   Well-being        10331 non-null  float64\n",
      " 3   Needs             10331 non-null  float64\n",
      " 4   Engagement        10331 non-null  float64\n",
      " 5   Autonomy          10331 non-null  float64\n",
      " 6   Belonging         10331 non-null  float64\n",
      " 7   Competence        10331 non-null  float64\n",
      " 8   Leadership        10331 non-null  float64\n",
      " 9   Management        10331 non-null  float64\n",
      " 10  Returns           10331 non-null  float64\n",
      " 11  Rewards           10331 non-null  float64\n",
      " 12  Status            10331 non-null  float64\n",
      " 13  Myself            10331 non-null  int64  \n",
      " 14  Tasks             10331 non-null  int64  \n",
      " 15  Free              10331 non-null  int64  \n",
      " 16  Mastery           10331 non-null  int64  \n",
      " 17  Competent         10331 non-null  int64  \n",
      " 18  Learn             10331 non-null  int64  \n",
      " 19  Group             10331 non-null  int64  \n",
      " 20  Talk              10331 non-null  int64  \n",
      " 21  Care              10331 non-null  int64  \n",
      " 22  Satisfied         10331 non-null  int64  \n",
      " 23  Meaning           10331 non-null  int64  \n",
      " 24  Stay              10331 non-null  int64  \n",
      " 25  Ideas             10331 non-null  int64  \n",
      " 26  Values            10331 non-null  int64  \n",
      " 27  Understands       10331 non-null  int64  \n",
      " 28  Encourages        10331 non-null  int64  \n",
      " 29  Listens           10331 non-null  int64  \n",
      " 30  Network           10331 non-null  int64  \n",
      " 31  Friendly          10331 non-null  int64  \n",
      " 32  Team              10331 non-null  int64  \n",
      " 33  Appreciated       10331 non-null  int64  \n",
      " 34  Responsibilities  10331 non-null  int64  \n",
      " 35  Work              10331 non-null  int64  \n",
      " 36  Impact            10331 non-null  int64  \n",
      " 37  Strong            10331 non-null  int64  \n",
      " 38  Drained           10331 non-null  int64  \n",
      " 39  Frustrated        10331 non-null  int64  \n",
      " 40  Volunteer         10331 non-null  int64  \n",
      " 41  Staff             10331 non-null  int64  \n",
      " 42  Position          10331 non-null  object \n",
      " 43  Country           10331 non-null  object \n",
      " 44  Region            10331 non-null  object \n",
      "dtypes: float64(11), int64(29), object(5)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# STEP 3\n",
    "# Assign Country and Region based on Team Name\n",
    "# 3.1 Assign a country to each team\n",
    "# 3.2 Assign a region to each country\n",
    "\n",
    "with open(\"Team_Country_Region_allocation.py\", encoding='utf-8') as file:\n",
    "    exec(file.read())\n",
    "\n",
    "# output file: 'Individual.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c3404e4-0e15-449a-a7e3-12bde8e79ff0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Country  size (n)\n",
      "5     Bahamas         2\n",
      "17  Indonesia         1\n",
      "33     Serbia         1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47 entries, 0 to 46\n",
      "Data columns (total 81 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Region                   47 non-null     object \n",
      " 1   Country                  47 non-null     object \n",
      " 2   Position                 47 non-null     object \n",
      " 3   size (n)                 47 non-null     int64  \n",
      " 4   nTeams                   47 non-null     int64  \n",
      " 5   Well-being_mean          47 non-null     float64\n",
      " 6   Needs_mean               47 non-null     float64\n",
      " 7   Engagement_mean          47 non-null     float64\n",
      " 8   Autonomy_mean            47 non-null     float64\n",
      " 9   Belonging_mean           47 non-null     float64\n",
      " 10  Competence_mean          47 non-null     float64\n",
      " 11  Leadership_mean          47 non-null     float64\n",
      " 12  Management_mean          47 non-null     float64\n",
      " 13  Returns_mean             47 non-null     float64\n",
      " 14  Rewards_mean             47 non-null     float64\n",
      " 15  Status_mean              47 non-null     float64\n",
      " 16  Myself_mean              47 non-null     float64\n",
      " 17  Tasks_mean               47 non-null     float64\n",
      " 18  Free_mean                47 non-null     float64\n",
      " 19  Mastery_mean             47 non-null     float64\n",
      " 20  Competent_mean           47 non-null     float64\n",
      " 21  Learn_mean               47 non-null     float64\n",
      " 22  Group_mean               47 non-null     float64\n",
      " 23  Talk_mean                47 non-null     float64\n",
      " 24  Care_mean                47 non-null     float64\n",
      " 25  Satisfied_mean           47 non-null     float64\n",
      " 26  Meaning_mean             47 non-null     float64\n",
      " 27  Stay_mean                47 non-null     float64\n",
      " 28  Ideas_mean               47 non-null     float64\n",
      " 29  Values_mean              47 non-null     float64\n",
      " 30  Understands_mean         47 non-null     float64\n",
      " 31  Encourages_mean          47 non-null     float64\n",
      " 32  Listens_mean             47 non-null     float64\n",
      " 33  Network_mean             47 non-null     float64\n",
      " 34  Friendly_mean            47 non-null     float64\n",
      " 35  Team_mean                47 non-null     float64\n",
      " 36  Appreciated_mean         47 non-null     float64\n",
      " 37  Responsibilities_mean    47 non-null     float64\n",
      " 38  Work_mean                47 non-null     float64\n",
      " 39  Impact_mean              47 non-null     float64\n",
      " 40  Strong_mean              47 non-null     float64\n",
      " 41  Drained_mean             47 non-null     float64\n",
      " 42  Frustrated_mean          47 non-null     float64\n",
      " 43  Well-being_median        47 non-null     float64\n",
      " 44  Needs_median             47 non-null     float64\n",
      " 45  Engagement_median        47 non-null     float64\n",
      " 46  Autonomy_median          47 non-null     float64\n",
      " 47  Belonging_median         47 non-null     float64\n",
      " 48  Competence_median        47 non-null     float64\n",
      " 49  Leadership_median        47 non-null     float64\n",
      " 50  Management_median        47 non-null     float64\n",
      " 51  Returns_median           47 non-null     float64\n",
      " 52  Rewards_median           47 non-null     float64\n",
      " 53  Status_median            47 non-null     float64\n",
      " 54  Myself_median            47 non-null     float64\n",
      " 55  Tasks_median             47 non-null     float64\n",
      " 56  Free_median              47 non-null     float64\n",
      " 57  Mastery_median           47 non-null     float64\n",
      " 58  Competent_median         47 non-null     float64\n",
      " 59  Learn_median             47 non-null     float64\n",
      " 60  Group_median             47 non-null     float64\n",
      " 61  Talk_median              47 non-null     float64\n",
      " 62  Care_median              47 non-null     float64\n",
      " 63  Satisfied_median         47 non-null     float64\n",
      " 64  Meaning_median           47 non-null     float64\n",
      " 65  Stay_median              47 non-null     float64\n",
      " 66  Ideas_median             47 non-null     float64\n",
      " 67  Values_median            47 non-null     float64\n",
      " 68  Understands_median       47 non-null     float64\n",
      " 69  Encourages_median        47 non-null     float64\n",
      " 70  Listens_median           47 non-null     float64\n",
      " 71  Network_median           47 non-null     float64\n",
      " 72  Friendly_median          47 non-null     float64\n",
      " 73  Team_median              47 non-null     float64\n",
      " 74  Appreciated_median       47 non-null     float64\n",
      " 75  Responsibilities_median  47 non-null     float64\n",
      " 76  Work_median              47 non-null     float64\n",
      " 77  Impact_median            47 non-null     float64\n",
      " 78  Strong_median            47 non-null     float64\n",
      " 79  Drained_median           47 non-null     float64\n",
      " 80  Frustrated_median        47 non-null     float64\n",
      "dtypes: float64(76), int64(2), object(3)\n",
      "memory usage: 29.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: Country tables, one for volunteers, one for staff and one for all.\n",
    "# unfinished: select Position=volunteers and then repeat for staff\n",
    "\n",
    "df = pd.read_csv(\"Individual.csv\", encoding='utf-8')\n",
    "\n",
    "# STEP 4.1: Group rows by 'Country' and calculate size (count) for each group\n",
    "## for ALL, i.e. no more distinctions between volunteers and staff\n",
    "country_df = df.groupby(['Region', 'Country', 'Position']).size().reset_index(name='size (n)')\n",
    "\n",
    "# Filter numeric columns for mean and median calculations\n",
    "numeric_cols = df.select_dtypes(include='number').columns\n",
    "\n",
    "# Calculate the mean and median for each column\n",
    "mean_df = df.groupby(['Region', 'Country', 'Position'])[numeric_cols].mean().round(1).reset_index()\n",
    "median_df = df.groupby(['Region', 'Country', 'Position'])[numeric_cols].median().round(1).reset_index()\n",
    "\n",
    "# Count unique occurrences of 'Team Name' for each country\n",
    "n_teams_df = df.groupby(['Region', 'Country', 'Position'])['Team Name'].nunique().reset_index(name='nTeams')\n",
    "\n",
    "# Merge the size (count), mean, median, and nTeams DataFrames\n",
    "#country_df = country_df.merge(n_teams_df, on='Country').merge(mean_df, on='Country', suffixes=('_mean', '_median')).merge(median_df, on='Country', suffixes=('_mean', '_median'))\n",
    "\n",
    "# Merge the size (count), mean, median, and nTeams DataFrames on 'Country' and 'Position'\n",
    "country_df = country_df.merge(n_teams_df, on=['Region', 'Country', 'Position']) \\\n",
    "                       .merge(mean_df, on=['Region', 'Country', 'Position'], suffixes=('_mean', '_median')) \\\n",
    "                       .merge(median_df, on=['Region', 'Country', 'Position'], suffixes=('_mean', '_median'))\n",
    "\n",
    "# Clean staff and volnteer columns\n",
    "#country_df['Volunteer'] = country_df['Volunteer_median'].round(0).astype(int)\n",
    "#country_df['Staff'] = country_df['Staff_median'].round(0).astype(int)\n",
    "#country_df.shape\n",
    "\n",
    "# Drop useless columns from the DataFrame\n",
    "country_df = country_df.drop(columns=['Volunteer_median', 'Volunteer_mean','Staff_median', 'Staff_mean'])\n",
    "\n",
    "# STEP 4.2. Identify, and check illigitemate ballots where team size smaller than 4\n",
    "# there is a minor issue here - we drop teams < 4 after the groupby country.\n",
    "# so when we group by country from the Individual.csv dataset the dropped individuals \n",
    "# are included in the country means and median scores.\n",
    "# since the proportion of individuals that are dropped is small, we can ignore this issue for now.\n",
    "\n",
    "df = country_df\n",
    "df.shape\n",
    "\n",
    "# How many small teams are we talking about?\n",
    "dropped_small_teams_df = df[df['size (n)'] < 4][['Country', 'size (n)']].copy()\n",
    "print(dropped_small_teams_df)\n",
    "dropped_small_teams_df.shape\n",
    "\n",
    "# Drop illigitemate teams from country dataset\n",
    "df = df.drop(df[df['size (n)'] < 4].index)\n",
    "df.shape\n",
    "\n",
    "country_df.to_csv('Country.csv', index=False)\n",
    "country_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f732c9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5 Team tables, all respondents, volunteers and staff alike.\n",
    "\n",
    "# Group rows by 'Team Name' and calculate size (count) for each group\n",
    "df = pd.read_csv(\"Individual.csv\", encoding='utf-8')\n",
    "\n",
    "## for ALL, i.e. no more distinctions between volunteers and staff\n",
    "team_df = df.groupby(['Team Name', 'Country', 'Region', 'Position']).size().reset_index(name='size (n)')\n",
    "\n",
    "# Filter numeric columns for mean and median calculations\n",
    "numeric_cols = df.select_dtypes(include='number').columns\n",
    "\n",
    "# Calculate the mean and median for each column\n",
    "mean_df = df.groupby('Team Name')[numeric_cols].mean().round(1).reset_index()\n",
    "median_df = df.groupby('Team Name')[numeric_cols].median().round(1).reset_index()\n",
    "\n",
    "# Merge the size (count), mean, median, and nTeams DataFrames\n",
    "team_df = team_df.merge(mean_df, on='Team Name', suffixes=('_mean', '_median')).merge(median_df, on='Team Name', suffixes=('_mean', '_median'))\n",
    "\n",
    "# Clean staff and volnteer columns\n",
    "team_df['Volunteer'] = team_df['Volunteer_median'].round(0).astype(int)\n",
    "team_df['Staff'] = team_df['Staff_median'].round(0).astype(int)\n",
    "# Drop useless columns from the DataFrame\n",
    "team_df = team_df.drop(columns=['Volunteer_median', 'Volunteer_mean','Staff_median', 'Staff_mean'])\n",
    "\n",
    "team_df.shape\n",
    "team_df.to_csv('Team.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d53841-4ac7-46e8-baf6-e1bdb8723571",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Position'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\anaconda3\\envs\\MotiSurveyData\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Position'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcountry_ALL.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m## for VOL, i.e.  volunteers only\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Filter the dataframe for 'Position' = 'Volunteer'\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPosition\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVolunteer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     10\u001b[0m country_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;241m.\u001b[39mreset_index(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize (n)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Filter numeric columns for mean and median calculations\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\anaconda3\\envs\\MotiSurveyData\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\anaconda3\\envs\\MotiSurveyData\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Position'"
     ]
    }
   ],
   "source": [
    "# STEP 3: country tables, one for volunteers, one for staff and one for all.\n",
    "# STEP 3.VOL: country tables volunteers only\n",
    "\n",
    "# 3.1.VOL Group rows by 'Country' and calculate size (count) for each group\n",
    "df = pd.read_csv(\"country_ALL.txt\", encoding='utf-8')\n",
    "\n",
    "## for VOL, i.e.  volunteers only\n",
    "# Filter the dataframe for 'Position' = 'Volunteer'\n",
    "df = df[df['Position'] == 'Volunteer']\n",
    "country_df = df.groupby('Country').size().reset_index(name='size (n)')\n",
    "\n",
    "# Filter numeric columns for mean and median calculations\n",
    "numeric_cols = df.select_dtypes(include='number').columns\n",
    "\n",
    "# 3.2.VOL Calculate the mean and median for each column\n",
    "mean_df = df.groupby('Country')[numeric_cols].mean().reset_index()\n",
    "median_df = df.groupby('Country')[numeric_cols].median().reset_index()\n",
    "\n",
    "# 3.3.VOL Count unique occurrences of 'Team Name' for each country\n",
    "n_teams_df = df.groupby('Country')['Team Name'].nunique().reset_index(name='nTeams')\n",
    "\n",
    "# 3.4.ALL Merge the size (count), mean, median, and nTeams DataFrames\n",
    "country_df = country_df.merge(n_teams_df, on='Country').merge(mean_df, on='Country', suffixes=('_mean', '_median')).merge(median_df, on='Country', suffixes=('_mean', '_median'))\n",
    "\n",
    "country_df.shape\n",
    "\n",
    "# STEP 3.5.VOL  Identify, and check illigitamate survey ballots where team size smaller than 4\n",
    "# there is a logic issue here - we cannot get rid of teams < 4 after groupby country.\n",
    "# if we groupby country from the teamsALL dataset then the means and averages will be wrong...\n",
    "\n",
    "df = country_df\n",
    "\n",
    "# How many small teams are we talking about?\n",
    "dropped_small_teams_df = df[df['size (n)'] < 4][['Country', 'size (n)']].copy()\n",
    "print(dropped_small_teams_df)\n",
    "dropped_small_teams_df.shape\n",
    "\n",
    "# STEP 3.6.VOL  Drop from illigitamate teams from country dataset\n",
    "df = df.drop(df[df['size (n)'] < 4].index)\n",
    "df.shape\n",
    "\n",
    "# STEP 3.7.VOL  Export country-level aggregations to Excel\n",
    "#country_df.to_excel('country_VOL.xlsx', index=False)\n",
    "country_df.to_csv('country_VOL.txt', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a147e4e5-2afc-4f5a-9e5d-1a2cbe5a7b50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 83)\n",
      "                country  size (n)\n",
      "0               Austria         1\n",
      "1                Cyprus         1\n",
      "2                    DK         1\n",
      "3               Ecuador         1\n",
      "4           El Salvador         1\n",
      "5              Ethiopia         1\n",
      "6               Finland         1\n",
      "7                Gambia         1\n",
      "8              Honduras         1\n",
      "9          IFRC network         1\n",
      "10           Kyrgyzstan         1\n",
      "11              Lebanon         1\n",
      "12               Mexico         1\n",
      "13             Mongolia         1\n",
      "14             Paraguay         1\n",
      "15             Portugal         1\n",
      "16             Salvador         1\n",
      "17                Samoa         1\n",
      "18                Spain         1\n",
      "19          Switzerland         1\n",
      "20                Tonga         1\n",
      "21  Trinidad and Tobago         1\n",
      "22              Ukraine         1\n",
      "23                 test         1\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: country tables, one for volunteers, one for staff and one for all.\n",
    "# STEP 3.STAFF: country tables staff only\n",
    "\n",
    "# 3.1.STAFF Group rows by 'Country' and calculate size (count) for each group\n",
    "if 'country' in df.columns:\n",
    "    country_df = df.groupby('country').size().reset_index(name='size (n)')\n",
    "else:\n",
    "    country_df = pd.DataFrame(columns=['country', 'size (n)'])\n",
    "\n",
    "# 3.4.ALL Merge the size (count), mean, median, and nTeams DataFrames\n",
    "country_df = country_df.merge(n_teams_df, on='country').merge(mean_df, on='country', suffixes=('_mean', '_median')).merge(median_df, on='country', suffixes=('_mean', '_median'))\n",
    "\n",
    "\n",
    "print(country_df.shape)\n",
    "\n",
    "# STEP 3.5.STAFF  Identify, and check illigitamate survey ballots where team size smaller than 4\n",
    "# there is a logic issue here - we cannot get rid of teams < 4 after groupby country.\n",
    "# if we groupby country from the teamsALL dataset then the means and averages will be wrong...\n",
    "\n",
    "df = country_df\n",
    "\n",
    "# How many small teams are we talking about?\n",
    "dropped_small_teams_df = df[df['size (n)'] < 4][['country', 'size (n)']].copy()\n",
    "print(dropped_small_teams_df)\n",
    "dropped_small_teams_df.shape\n",
    "\n",
    "# STEP 3.6.STAFF  Drop from illigitamate teams from country dataset\n",
    "df = df.drop(df[df['size (n)'] < 4].index)\n",
    "df.shape\n",
    "\n",
    "# STEP 3.7.STAFF  Export country-level aggregations to Excel\n",
    "#country_df.to_excel('country_STAFF.xlsx', index=False)\n",
    "country_df.to_csv('country_STAFF.txt', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef4812cc-b953-4bc3-be9c-a80b2fdcdc8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9705 entries, 0 to 9704\n",
      "Data columns (total 44 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Team Name         9705 non-null   object \n",
      " 1   Well-being        9705 non-null   float64\n",
      " 2   Needs             9705 non-null   float64\n",
      " 3   Engagement        9705 non-null   float64\n",
      " 4   Autonomy          9705 non-null   float64\n",
      " 5   Belonging         9705 non-null   float64\n",
      " 6   Competence        9705 non-null   float64\n",
      " 7   Leadership        9705 non-null   float64\n",
      " 8   Management        9705 non-null   float64\n",
      " 9   Returns           9705 non-null   float64\n",
      " 10  Rewards           9705 non-null   float64\n",
      " 11  Status            9705 non-null   float64\n",
      " 12  Myself            9705 non-null   int64  \n",
      " 13  Tasks             9705 non-null   int64  \n",
      " 14  Free              9705 non-null   int64  \n",
      " 15  Mastery           9705 non-null   int64  \n",
      " 16  Competent         9705 non-null   int64  \n",
      " 17  Learn             9705 non-null   int64  \n",
      " 18  Group             9705 non-null   int64  \n",
      " 19  Talk              9705 non-null   int64  \n",
      " 20  Care              9705 non-null   int64  \n",
      " 21  Satisfied         9705 non-null   int64  \n",
      " 22  Meaning           9705 non-null   int64  \n",
      " 23  Stay              9705 non-null   int64  \n",
      " 24  Ideas             9705 non-null   int64  \n",
      " 25  Values            9705 non-null   int64  \n",
      " 26  Understands       9705 non-null   int64  \n",
      " 27  Encourages        9705 non-null   int64  \n",
      " 28  Listens           9705 non-null   int64  \n",
      " 29  Network           9705 non-null   int64  \n",
      " 30  Friendly          9705 non-null   int64  \n",
      " 31  Team              9705 non-null   int64  \n",
      " 32  Appreciated       9705 non-null   int64  \n",
      " 33  Responsibilities  9705 non-null   int64  \n",
      " 34  Work              9705 non-null   int64  \n",
      " 35  Impact            9705 non-null   int64  \n",
      " 36  Strong            9705 non-null   int64  \n",
      " 37  Drained           9705 non-null   int64  \n",
      " 38  Frustrated        9705 non-null   int64  \n",
      " 39  Volunteer         9705 non-null   int64  \n",
      " 40  Staff             9705 non-null   int64  \n",
      " 41  Position          9705 non-null   object \n",
      " 42  Country           9506 non-null   object \n",
      " 43  Region            9506 non-null   object \n",
      "dtypes: float64(11), int64(29), object(4)\n",
      "memory usage: 3.3+ MB\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mean_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m team_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeam Name\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;241m.\u001b[39mreset_index(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize (n)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# STEP 4.2  Merge the size (count), mean, median, and country DataFrames\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m team_df \u001b[38;5;241m=\u001b[39m team_df\u001b[38;5;241m.\u001b[39mmerge(mean_df, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeam Name\u001b[39m\u001b[38;5;124m'\u001b[39m, suffixes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_mean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_median\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mmerge(median_df, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeam Name\u001b[39m\u001b[38;5;124m'\u001b[39m, suffixes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_mean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_median\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mmerge(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeam Name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcountry\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPosition\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdrop_duplicates(), on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeam Name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m team_df\u001b[38;5;241m.\u001b[39minfo()\n\u001b[0;32m     15\u001b[0m team_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteam_ALL.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mean_df' is not defined"
     ]
    }
   ],
   "source": [
    "# STEP 4: create dataframe where one row is one team\n",
    "\n",
    "# STEP 4.1 Group rows by 'Team Name' and calculate size (count) for each team\n",
    "# Load the dataframe from \"ungrouped_ALL_with_regions.txt\"\n",
    "file_path = \"ungrouped_ALL_with_regions.txt\"\n",
    "df = pd.read_csv(file_path, sep=\",\", encoding='utf-8')\n",
    "\n",
    "df.info()\n",
    "team_df = df.groupby('Team Name').size().reset_index(name='size (n)')\n",
    "\n",
    "\n",
    "# STEP 4.2  Merge the size (count), mean, median, and country DataFrames\n",
    "team_df = team_df.merge(mean_df, on='Team Name', suffixes=('_mean', '_median')).merge(median_df, on='Team Name', suffixes=('_mean', '_median')).merge(df[['Team Name', 'country', 'Position']].drop_duplicates(), on='Team Name')\n",
    "team_df.info()\n",
    "team_df.to_csv('team_ALL.txt', index=False)\n",
    "\n",
    "## create an short table without survey results\n",
    "#team_df = team_df.merge(df[['Team Name', 'Country', 'Position']].drop_duplicates(), on='Team Name')\n",
    "#team_df.to_csv('team_ALL_short.txt', index=False)\n",
    "#team_df.info()\n",
    "\n",
    "# STEP 4.3  \n",
    "# For ALL (Volunteers and staff) - create files with Teams data\n",
    "#team_df.to_excel('team_ALL.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4997148-a346-4651-b438-40267ff94dca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

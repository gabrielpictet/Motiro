{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a0ae26c-d722-4354-9f63-12aa10ae09ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9937a37-f270-405c-a095-c3d80bb2b196",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabriel.pictet\\AppData\\Local\\Temp\\ipykernel_18044\\3483443009.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].replace(mapping)\n",
      "C:\\Users\\gabriel.pictet\\AppData\\Local\\Temp\\ipykernel_18044\\3483443009.py:41: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['At my volunteer activity, I feel strong and vigorous.'] = df['At my volunteer activity, I feel strong and vigorous.'].replace(mapping)\n",
      "C:\\Users\\gabriel.pictet\\AppData\\Local\\Temp\\ipykernel_18044\\3483443009.py:42: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['I feel emotionally drained from my volunteer activity.'] = df['I feel emotionally drained from my volunteer activity.'].replace(mapping)\n",
      "C:\\Users\\gabriel.pictet\\AppData\\Local\\Temp\\ipykernel_18044\\3483443009.py:43: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['I feel frustrated by my volunteer activity.'] = df['I feel frustrated by my volunteer activity.'].replace(mapping)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9195 entries, 0 to 9194\n",
      "Data columns (total 42 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Myself                       9195 non-null   int64  \n",
      " 1   Tasks                        9195 non-null   int64  \n",
      " 2   Free                         9195 non-null   int64  \n",
      " 3   Mastery                      9195 non-null   int64  \n",
      " 4   Competent                    9195 non-null   int64  \n",
      " 5   Learn                        9195 non-null   int64  \n",
      " 6   Group                        9195 non-null   int64  \n",
      " 7   Talk                         9195 non-null   int64  \n",
      " 8   Care                         9195 non-null   int64  \n",
      " 9   Satisfied                    9195 non-null   int64  \n",
      " 10  Meaning                      9195 non-null   int64  \n",
      " 11  Stay                         9195 non-null   int64  \n",
      " 12  Ideas                        9195 non-null   int64  \n",
      " 13  Values                       9195 non-null   int64  \n",
      " 14  Understands                  9195 non-null   int64  \n",
      " 15  Encourages                   9195 non-null   int64  \n",
      " 16  Listens                      9195 non-null   int64  \n",
      " 17  Network                      9195 non-null   int64  \n",
      " 18  Friendly                     9195 non-null   int64  \n",
      " 19  Team                         9195 non-null   int64  \n",
      " 20  Appreciated                  9195 non-null   int64  \n",
      " 21  Responsibilities             9195 non-null   int64  \n",
      " 22  Work                         9195 non-null   int64  \n",
      " 23  Impact                       9195 non-null   int64  \n",
      " 24  Strong                       9195 non-null   int64  \n",
      " 25  Drained                      9195 non-null   int64  \n",
      " 26  Frustrated                   9195 non-null   int64  \n",
      " 27  What year were you born in?  0 non-null      float64\n",
      " 28  What is your gender?         0 non-null      float64\n",
      " 29  Team Name                    9195 non-null   object \n",
      " 30  Survey Data                  9195 non-null   object \n",
      " 31  Well-being                   9195 non-null   float64\n",
      " 32  Engagement                   9195 non-null   float64\n",
      " 33  Autonomy                     9195 non-null   float64\n",
      " 34  Belonging                    9195 non-null   float64\n",
      " 35  Competence                   9195 non-null   float64\n",
      " 36  Needs                        9195 non-null   float64\n",
      " 37  Leadership                   9195 non-null   float64\n",
      " 38  Management                   9195 non-null   float64\n",
      " 39  Returns                      9195 non-null   float64\n",
      " 40  Rewards                      9195 non-null   float64\n",
      " 41  Status                       9195 non-null   float64\n",
      "dtypes: float64(13), int64(27), object(2)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# VOLUNTEERS - step 1\n",
    "# Read the uploaded .txt file with an alternative encoding\n",
    "# The csv file is corrupted by MS Excel so it needs to be opened in notepad and saved as a .txt file\n",
    "file_path = 'C:/Users/gabriel.pictet/Documents/Gabriel/REAL/Moti/Moti data/answers-volunteers.txt'\n",
    "df = pd.read_csv(file_path, sep=\",\", encoding='utf-8')\n",
    "#alternative encoding not working: df = pd.read_csv(file_path, sep=\",\", encoding='cp1252')\n",
    "# Display the last rows of the dataframe to verify successful loading\n",
    "df.tail()\n",
    "\n",
    "# STEP 1.1v : recoding answers from string to integer in order to compute scores and means\n",
    "\n",
    "# Define the mapping of categorical values to integers\n",
    "mapping = {\n",
    "    'Strongly disagree': 1,\n",
    "    'Somewhat disagree': 2,\n",
    "    'Neutral': 3,\n",
    "    'Somewhat agree': 4,\n",
    "    'Strongly agree': 5\n",
    "}\n",
    "\n",
    "# For the 24 first columns, transform the categorical column into integers using the mapping\n",
    "\n",
    "for col in df.columns[:24]:\n",
    "    df[col] = df[col].replace(mapping)\n",
    "\n",
    "#replace string values with real numbers 1-7 to compute means for frequency variable, by teams\n",
    "# At my volunteer activity, I feel strong and vigorous      column[24]     \n",
    "# I feel emotionally drained from my work.                  column[25]     \n",
    "# I feel frustrated by my work.                             column[26]  \n",
    "\n",
    "mapping = {\n",
    "    \"Every time\": 7,\n",
    "    \"Very often\": 6,\n",
    "    \"Often\": 5,\n",
    "    \"Sometimes\": 4,\n",
    "    \"Rarely\": 3,\n",
    "    \"Almost never\": 2,\n",
    "    \"Never\": 1\n",
    "} \n",
    "\n",
    "df['At my volunteer activity, I feel strong and vigorous.'] = df['At my volunteer activity, I feel strong and vigorous.'].replace(mapping)\n",
    "df['I feel emotionally drained from my volunteer activity.'] = df['I feel emotionally drained from my volunteer activity.'].replace(mapping)\n",
    "df['I feel frustrated by my volunteer activity.'] = df['I feel frustrated by my volunteer activity.'].replace(mapping)\n",
    "\n",
    "df.head()\n",
    "# VOLUNTEERS\n",
    "# STEP 1.2v : Create the scores for each dimension, e.g. autonomy, belonging, etc.\n",
    "#  Before computing the well-being score: \n",
    "#  recode the two following columns so that the positive outcomes get the higher scores\n",
    "# 'I feel emotionally drained from my volunteer activity.\n",
    "# 'I feel frustrated by my volunteer activity.\n",
    "\n",
    "mapping = {\n",
    "    7: 1,\n",
    "    6: 2,\n",
    "    5: 3,\n",
    "    4: 4,\n",
    "    3: 5,\n",
    "    2: 6,\n",
    "    1: 7\n",
    "}\n",
    "\n",
    "df['I feel emotionally drained from my volunteer activity.'] = df['I feel emotionally drained from my volunteer activity.'].replace(mapping)\n",
    "df['I feel frustrated by my volunteer activity.'] = df['I feel frustrated by my volunteer activity.'].replace(mapping)\n",
    "\n",
    "# Specify the column names for Well-being\n",
    "column_names = [\n",
    "    'At my volunteer activity, I feel strong and vigorous.',\n",
    "    'I feel emotionally drained from my volunteer activity.',\n",
    "    'I feel frustrated by my volunteer activity.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Well-being'\n",
    "df['Well-being'] = df[column_names].mean(axis=1)\n",
    "\n",
    "# Rescale the 'Well-being' values from a range of 1-7 to 1-5 and runds the result\n",
    "df['Well-being'] = (df['Well-being'] - 1) * (4 / 6) + 1\n",
    "df['Well-being'] = df['Well-being'].round(1)\n",
    "\n",
    "## recode back to original values for the two \"negative\" variables\n",
    "#  after computing the well-being score for \"logical\" correlation analysis\n",
    "#  we need to recode the two following columns so that the negative outcomes get the higher scores\n",
    "# 'I feel emotionally drained from my volunteer activity.\n",
    "# 'I feel frustrated by my volunteer activity.\n",
    "\n",
    "mapping = {\n",
    "    7: 1,\n",
    "    6: 2,\n",
    "    5: 3,\n",
    "    4: 4,\n",
    "    3: 5,\n",
    "    2: 6,\n",
    "    1: 7\n",
    "}\n",
    "\n",
    "df['I feel emotionally drained from my volunteer activity.'] = df['I feel emotionally drained from my volunteer activity.'].replace(mapping)\n",
    "df['I feel frustrated by my volunteer activity.'] = df['I feel frustrated by my volunteer activity.'].replace(mapping)\n",
    "\n",
    "\n",
    "# Specify the column names for Engagement\n",
    "column_names = [\n",
    "    'If I could choose, I will be volunteering one year from now.',\n",
    "    'The team has a great deal of personal meaning for me.',\n",
    "    'Considering everything, I am satisfied with my volunteer activity.',\n",
    "    'I share my ideas with others to improve the team.',\n",
    "    'The things that I value in life are very similar to the things that the team values.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Engagement'\n",
    "df['Engagement'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for Autonomy\n",
    "column_names = [\n",
    "    'I feel like I can be myself at my volunteer activity.',\n",
    "    'The tasks I must do at my volunteer activity are in line with what I really want to do.',\n",
    "    'I am free to express my ideas and opinions on the volunteer activity.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Autonomy'\n",
    "df['Autonomy'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for belonging\n",
    "column_names = [\n",
    "    'At my volunteer activity, I feel part of a group.',\n",
    "    'At my volunteer activity, I can talk with people about things that really matter to me.',\n",
    "    'People at my volunteer activity care about me.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Belonging'\n",
    "df['Belonging'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for Competence\n",
    "column_names = [\n",
    "    'I really master my tasks at my volunteer activity.',\n",
    "    'I feel competent at my volunteer activity.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Competence'\n",
    "df['Competence'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for Needs\n",
    "column_names = [\n",
    "    'I feel like I can be myself at my volunteer activity.',\n",
    "    'The tasks I must do at my volunteer activity are in line with what I really want to do.',\n",
    "    'I am free to express my ideas and opinions on the volunteer activity.',\n",
    "    'At my volunteer activity, I feel part of a group.',\n",
    "    'At my volunteer activity, I can talk with people about things that really matter to me.',\n",
    "    'People at my volunteer activity care about me.',\n",
    "    'I really master my tasks at my volunteer activity.',\n",
    "    'I feel competent at my volunteer activity.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Needs'\n",
    "df['Needs'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for Leadership\n",
    "column_names = [\n",
    "    'My supervisor listens to how I would like to do things.',\n",
    "    'I feel understood by my supervisor.',\n",
    "    'My supervisor encourages me to ask questions.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Leadership'\n",
    "df['Leadership'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for 'Management'\n",
    "column_names = [\n",
    "    'I have the opportunity to develop my social network in my volunteer activity.',\n",
    "    'I have been able to learn interesting new skills on my volunteer activity.',\n",
    "    'I am fairly rewarded considering the responsibilities I have.',\n",
    "    'I am fairly rewarded for the work I do well.',\n",
    "    'My family, friends and my neighborhood appreciate the work I do for the team.',\n",
    "    'I feel my work has positive impact on other people.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Management'\n",
    "df['Management'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for 'Returns'\n",
    "column_names = [\n",
    "    'I have the opportunity to develop my social network in my volunteer activity.',\n",
    "    'I have been able to learn interesting new skills on my volunteer activity.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Returns'\n",
    "df['Returns'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for 'Rewards'\n",
    "column_names = [\n",
    "    'I am fairly rewarded considering the responsibilities I have.',\n",
    "    'I am fairly rewarded for the work I do well.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Rewards'\n",
    "df['Rewards'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for 'Status'\n",
    "column_names = [\n",
    "    'My family, friends and my neighborhood appreciate the work I do for the team.',\n",
    "    'I feel my work has positive impact on other people.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Status'\n",
    "df['Status'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "\n",
    "# STEP 1.3v : Rename columns in their abridged form to allow VOL-STAFF df concatenation\n",
    "cols_to_update = [\n",
    "    'Myself',\n",
    "    'Tasks',\n",
    "    'Free',\n",
    "    'Mastery',\n",
    "    'Competent',\n",
    "    'Learn',\n",
    "    'Group',\n",
    "    'Talk',\n",
    "    'Care',\n",
    "    'Satisfied',\n",
    "    'Meaning',\n",
    "    'Stay',\n",
    "    'Ideas',\n",
    "    'Values',\n",
    "    'Understands',\n",
    "    'Encourages',\n",
    "    'Listens',\n",
    "    'Network',\n",
    "    'Friendly',\n",
    "    'Team',\n",
    "    'Appreciated',\n",
    "    'Responsibilities',\n",
    "    'Work',\n",
    "    'Impact',\n",
    "    'Strong',\n",
    "    'Drained',\n",
    "    'Frustrated'\n",
    "    ] + df.columns[27:].tolist()\n",
    "\n",
    "df.columns = cols_to_update\n",
    "\n",
    "df.info()\n",
    "\n",
    "# STEP 1.4v : Export VOLUNTEER dataframe with composite indicators before grouping by teams\n",
    "ungrouped_df = df\n",
    "ungrouped_df.to_csv('ungrouped_volunteers.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4f104e3-a215-44de-a515-e2c411b9615b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1389 entries, 0 to 1388\n",
      "Data columns (total 42 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Myself                       1389 non-null   int64  \n",
      " 1   Tasks                        1389 non-null   int64  \n",
      " 2   Free                         1389 non-null   int64  \n",
      " 3   Mastery                      1389 non-null   int64  \n",
      " 4   Competent                    1389 non-null   int64  \n",
      " 5   Learn                        1389 non-null   int64  \n",
      " 6   Group                        1389 non-null   int64  \n",
      " 7   Talk                         1389 non-null   int64  \n",
      " 8   Care                         1389 non-null   int64  \n",
      " 9   Satisfied                    1389 non-null   int64  \n",
      " 10  Meaning                      1389 non-null   int64  \n",
      " 11  Stay                         1389 non-null   int64  \n",
      " 12  Ideas                        1389 non-null   int64  \n",
      " 13  Values                       1389 non-null   int64  \n",
      " 14  Understands                  1389 non-null   int64  \n",
      " 15  Encourages                   1389 non-null   int64  \n",
      " 16  Listens                      1389 non-null   int64  \n",
      " 17  Network                      1389 non-null   int64  \n",
      " 18  Friendly                     1389 non-null   int64  \n",
      " 19  Team                         1389 non-null   int64  \n",
      " 20  Appreciated                  1389 non-null   int64  \n",
      " 21  Responsibilities             1389 non-null   int64  \n",
      " 22  Work                         1389 non-null   int64  \n",
      " 23  Impact                       1389 non-null   int64  \n",
      " 24  Strong                       1389 non-null   int64  \n",
      " 25  Drained                      1389 non-null   int64  \n",
      " 26  Frustrated                   1389 non-null   int64  \n",
      " 27  What year were you born in?  0 non-null      float64\n",
      " 28  What is your gender?         0 non-null      float64\n",
      " 29  Team Name                    1389 non-null   object \n",
      " 30  Survey Data                  1389 non-null   object \n",
      " 31  Well-being                   1389 non-null   float64\n",
      " 32  Engagement                   1389 non-null   float64\n",
      " 33  Autonomy                     1389 non-null   float64\n",
      " 34  Belonging                    1389 non-null   float64\n",
      " 35  Competence                   1389 non-null   float64\n",
      " 36  Needs                        1389 non-null   float64\n",
      " 37  Leadership                   1389 non-null   float64\n",
      " 38  Management                   1389 non-null   float64\n",
      " 39  Returns                      1389 non-null   float64\n",
      " 40  Rewards                      1389 non-null   float64\n",
      " 41  Status                       1389 non-null   float64\n",
      "dtypes: float64(13), int64(27), object(2)\n",
      "memory usage: 455.9+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabriel.pictet\\AppData\\Local\\Temp\\ipykernel_18044\\2757185632.py:21: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].replace(mapping)\n",
      "C:\\Users\\gabriel.pictet\\AppData\\Local\\Temp\\ipykernel_18044\\2757185632.py:35: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['At work, I feel strong and vigorous.'] = df['At work, I feel strong and vigorous.'].replace(mapping)\n",
      "C:\\Users\\gabriel.pictet\\AppData\\Local\\Temp\\ipykernel_18044\\2757185632.py:36: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['I feel emotionally drained from my work.'] = df['I feel emotionally drained from my work.'].replace(mapping)\n",
      "C:\\Users\\gabriel.pictet\\AppData\\Local\\Temp\\ipykernel_18044\\2757185632.py:37: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['I feel frustrated by my work.'] = df['I feel frustrated by my work.'].replace(mapping)\n"
     ]
    }
   ],
   "source": [
    "# STAFF Step 1\n",
    "\n",
    "# Open the Raw Moti Data CSV file as sent by CE\n",
    "df = pd.read_csv(\"C:/Users/gabriel.pictet/Documents/Gabriel/REAL/Moti/Moti data/answers-staff.txt\", sep=\",\", encoding='utf-8')\n",
    "df.shape\n",
    "\n",
    "# STEP 1.1s : recode answers from string to integer in order to compute scores and means\n",
    "\n",
    "# Define the mapping of categorical values to integers\n",
    "mapping = {\n",
    "    'Strongly disagree': 1,\n",
    "    'Somewhat disagree': 2,\n",
    "    'Neutral': 3,\n",
    "    'Somewhat agree': 4,\n",
    "    'Strongly agree': 5\n",
    "}\n",
    "\n",
    "# For the 24 first columns, transform the categorical column into integers using the mapping\n",
    "\n",
    "for col in df.columns[:24]:\n",
    "    df[col] = df[col].replace(mapping)\n",
    "\n",
    "# replace string values with real numbers 1-7 for frequency variable, by teams\n",
    "\n",
    "mapping = {\n",
    "    \"Every day\": 7,\n",
    "    \"Very often\": 6,\n",
    "    \"Often\": 5,\n",
    "    \"Sometimes\": 4,\n",
    "    \"Rarely\": 3,\n",
    "    \"Almost never\": 2,\n",
    "    \"Never\": 1\n",
    "}\n",
    "\n",
    "df['At work, I feel strong and vigorous.'] = df['At work, I feel strong and vigorous.'].replace(mapping)\n",
    "df['I feel emotionally drained from my work.'] = df['I feel emotionally drained from my work.'].replace(mapping)\n",
    "df['I feel frustrated by my work.'] = df['I feel frustrated by my work.'].replace(mapping)\n",
    "\n",
    "\n",
    "# STEP 1.2s : Create the scores for each dimension, e.g. autonomy, belonging, etc.\n",
    "# NB: Change questions for staff data\n",
    "\n",
    "#  Before computing the well-being score \n",
    "#  we need to recode the two following columns so that the positive outcomes get the higher scores\n",
    "# 'I feel emotionally drained from my volunteer activity.\n",
    "# 'I feel frustrated by my volunteer activity.\n",
    "\n",
    "mapping = {\n",
    "    7: 1,\n",
    "    6: 2,\n",
    "    5: 3,\n",
    "    4: 4,\n",
    "    3: 5,\n",
    "    2: 6,\n",
    "    1: 7\n",
    "}\n",
    "\n",
    "df['I feel emotionally drained from my work.'] = df['I feel emotionally drained from my work.'].replace(mapping)\n",
    "df['I feel frustrated by my work.'] = df['I feel frustrated by my work.'].replace(mapping)\n",
    "\n",
    "# Specify the column names for Well-being\n",
    "column_names = [\n",
    "    'At work, I feel strong and vigorous.',\n",
    "    'I feel emotionally drained from my work.',\n",
    "    'I feel frustrated by my work.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Well-being'\n",
    "df['Well-being'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Rescale the 'Well-being' values from a range of 1-7 to 1-5 and runds the result\n",
    "df['Well-being'] = (df['Well-being'] - 1) * (4 / 6) + 1\n",
    "df['Well-being'] = df['Well-being'].round(1)\n",
    "\n",
    "## recode back to original values for the two \"negative\" variables\n",
    "#  after computing the well-being score for \"logical\" correlation analysis\n",
    "#  we need to recode the two following columns so that the negative outcomes get the higher scores\n",
    "# 'I feel emotionally drained from my work.\n",
    "# 'I feel frustrated by my work.\n",
    "\n",
    "mapping = {\n",
    "    7: 1,\n",
    "    6: 2,\n",
    "    5: 3,\n",
    "    4: 4,\n",
    "    3: 5,\n",
    "    2: 6,\n",
    "    1: 7\n",
    "}\n",
    "\n",
    "df['I feel emotionally drained from my work.'] = df['I feel emotionally drained from my work.'].replace(mapping)\n",
    "df['I feel frustrated by my work.'] = df['I feel frustrated by my work.'].replace(mapping)\n",
    "\n",
    "# Specify the column names for Engagement\n",
    "column_names = [\n",
    "    'If I could choose, I would continue working in my team one year from now.',\n",
    "    'The team means a lot to me personally.',\n",
    "    'Considering everything, I am satisfied with my work.',\n",
    "    'I share my ideas with others to improve the team.',\n",
    "    'The things that I value in life are very similar to the things that the team values.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Engagement'\n",
    "df['Engagement'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for Autonomy\n",
    "column_names = [\n",
    "    'I feel like I can be myself at work.',\n",
    "    'My tasks at my work are in line with what I really want to do.',\n",
    "    'I am free to express my ideas and opinions on my work.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Autonomy'\n",
    "df['Autonomy'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for belonging\n",
    "column_names = [\n",
    "    'At my work, I feel part of a group.',\n",
    "    'At my work, I can talk with people about things that really matter to me.',\n",
    "    'People at my work care about me.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Belonging'\n",
    "df['Belonging'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for Competence\n",
    "column_names = [\n",
    "    'I really master my tasks at work.',\n",
    "    'I feel competent at work.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Competence'\n",
    "df['Competence'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for Needs\n",
    "column_names = [\n",
    "    'I feel like I can be myself at work.',\n",
    "    'My tasks at my work are in line with what I really want to do.',\n",
    "    'I am free to express my ideas and opinions on my work.',\n",
    "    'At my work, I feel part of a group.',\n",
    "    'At my work, I can talk with people about things that really matter to me.',\n",
    "    'People at my work care about me.',\n",
    "    'I really master my tasks at work.',\n",
    "    'I feel competent at work.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Needs'\n",
    "df['Needs'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for Leadership\n",
    "column_names = [\n",
    "    'My supervisor listens to how I would like to do things.',\n",
    "    'I feel understood by my supervisor.',\n",
    "    'My supervisor encourages me to ask questions.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Leadership'\n",
    "df['Leadership'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for 'Management'\n",
    "column_names = [\n",
    "    'I have the opportunity to develop my social network at work.',\n",
    "    'I have been able to learn interesting new skills at work.',\n",
    "    'I am fairly rewarded considering the responsibilities I have.',\n",
    "    'I am fairly rewarded for the work I do well.',\n",
    "    'My family and friends appreciate the work I do for the team.',\n",
    "    'I feel my work has positive impact on other people.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Management'\n",
    "df['Management'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for 'Returns'\n",
    "column_names = [\n",
    "    'I have the opportunity to develop my social network at work.',\n",
    "    'I have been able to learn interesting new skills at work.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Returns'\n",
    "df['Returns'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for 'Rewards'\n",
    "column_names = [\n",
    "    'I am fairly rewarded considering the responsibilities I have.',\n",
    "    'I am fairly rewarded for the work I do well.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Rewards'\n",
    "df['Rewards'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# Specify the column names for 'Status'\n",
    "column_names = [\n",
    "    'My family and friends appreciate the work I do for the team.',\n",
    "    'I feel my work has positive impact on other people.'\n",
    "]\n",
    "\n",
    "# Calculate the mean row by row and assign it to a new column 'Status'\n",
    "df['Status'] = df[column_names].mean(axis=1).round(1)\n",
    "\n",
    "# STAFF   \n",
    "# STEP 1.3s : Rename columns in their abridged form to allow VOL-STAFF df concatenation\n",
    "cols_to_update = [\n",
    "    'Myself',\n",
    "    'Tasks',\n",
    "    'Free',\n",
    "    'Mastery',\n",
    "    'Competent',\n",
    "    'Learn',\n",
    "    'Group',\n",
    "    'Talk',\n",
    "    'Care',\n",
    "    'Satisfied',\n",
    "    'Meaning',\n",
    "    'Stay',\n",
    "    'Ideas',\n",
    "    'Values',\n",
    "    'Understands',\n",
    "    'Encourages',\n",
    "    'Listens',\n",
    "    'Network',\n",
    "    'Friendly',\n",
    "    'Team',\n",
    "    'Appreciated',\n",
    "    'Responsibilities',\n",
    "    'Work',\n",
    "    'Impact',\n",
    "    'Strong',\n",
    "    'Drained',\n",
    "    'Frustrated'\n",
    "    ] + df.columns[27:].tolist()\n",
    "\n",
    "df.columns = cols_to_update\n",
    "\n",
    "df.info()\n",
    "\n",
    "\n",
    "# STEP 1.4s : Export STAFF dataframe with composite indicators before grouping by teams\n",
    "ungrouped_df = df\n",
    "ungrouped_df.to_csv('ungrouped_staff.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c904d717-6cc0-4195-9a65-89e499fbb619",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10584 entries, 0 to 10583\n",
      "Data columns (total 43 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Team Name         10584 non-null  object \n",
      " 1   Survey Data       10584 non-null  object \n",
      " 2   Well-being        10584 non-null  float64\n",
      " 3   Needs             10584 non-null  float64\n",
      " 4   Engagement        10584 non-null  float64\n",
      " 5   Autonomy          10584 non-null  float64\n",
      " 6   Belonging         10584 non-null  float64\n",
      " 7   Competence        10584 non-null  float64\n",
      " 8   Leadership        10584 non-null  float64\n",
      " 9   Management        10584 non-null  float64\n",
      " 10  Returns           10584 non-null  float64\n",
      " 11  Rewards           10584 non-null  float64\n",
      " 12  Status            10584 non-null  float64\n",
      " 13  Myself            10584 non-null  int64  \n",
      " 14  Tasks             10584 non-null  int64  \n",
      " 15  Free              10584 non-null  int64  \n",
      " 16  Mastery           10584 non-null  int64  \n",
      " 17  Competent         10584 non-null  int64  \n",
      " 18  Learn             10584 non-null  int64  \n",
      " 19  Group             10584 non-null  int64  \n",
      " 20  Talk              10584 non-null  int64  \n",
      " 21  Care              10584 non-null  int64  \n",
      " 22  Satisfied         10584 non-null  int64  \n",
      " 23  Meaning           10584 non-null  int64  \n",
      " 24  Stay              10584 non-null  int64  \n",
      " 25  Ideas             10584 non-null  int64  \n",
      " 26  Values            10584 non-null  int64  \n",
      " 27  Understands       10584 non-null  int64  \n",
      " 28  Encourages        10584 non-null  int64  \n",
      " 29  Listens           10584 non-null  int64  \n",
      " 30  Network           10584 non-null  int64  \n",
      " 31  Friendly          10584 non-null  int64  \n",
      " 32  Team              10584 non-null  int64  \n",
      " 33  Appreciated       10584 non-null  int64  \n",
      " 34  Responsibilities  10584 non-null  int64  \n",
      " 35  Work              10584 non-null  int64  \n",
      " 36  Impact            10584 non-null  int64  \n",
      " 37  Strong            10584 non-null  int64  \n",
      " 38  Drained           10584 non-null  int64  \n",
      " 39  Frustrated        10584 non-null  int64  \n",
      " 40  Volunteer         10584 non-null  int64  \n",
      " 41  Staff             10584 non-null  int64  \n",
      " 42  Position          10584 non-null  object \n",
      "dtypes: float64(11), int64(29), object(3)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# STEP 2  -  MERGE into one data frame all ungrouped data with abridged column names\n",
    "\n",
    "# Define the columns to include in the merged dataframe\n",
    "columns = ['Team Name', 'Survey Data', 'Well-being', 'Needs', 'Engagement', 'Autonomy', 'Belonging',\n",
    "           'Competence', 'Leadership', 'Management', 'Returns',\n",
    "           'Rewards', 'Status',\n",
    "    'Myself',\n",
    "    'Tasks',\n",
    "    'Free',\n",
    "    'Mastery',\n",
    "    'Competent',\n",
    "    'Learn',\n",
    "    'Group',\n",
    "    'Talk',\n",
    "    'Care',\n",
    "    'Satisfied',\n",
    "    'Meaning',\n",
    "    'Stay',\n",
    "    'Ideas',\n",
    "    'Values',\n",
    "    'Understands',\n",
    "    'Encourages',\n",
    "    'Listens',\n",
    "    'Network',\n",
    "    'Friendly',\n",
    "    'Team',\n",
    "    'Appreciated',\n",
    "    'Responsibilities',\n",
    "    'Work',\n",
    "    'Impact',\n",
    "    'Strong',\n",
    "    'Drained',\n",
    "    'Frustrated']\n",
    "\n",
    "# Read VOLUNTEER dataframe\n",
    "df_VOL = pd.read_csv(\"ungrouped_volunteers.txt\", encoding='utf-8')\n",
    "\n",
    "# Create the table with the desired columns\n",
    "df_VOL = df_VOL[columns]\n",
    "\n",
    "# Round the values to one decimal point\n",
    "df_VOL = df_VOL.round(decimals=1)\n",
    "\n",
    "# Create a Volunteer dummy variable where Volunteer = 1\n",
    "df_VOL['Volunteer'] = 1\n",
    "df_VOL['Staff'] = 0\n",
    "df_VOL['Position'] = 'Volunteer'\n",
    "\n",
    "# Read STAFF dataframe\n",
    "df_STAFF = pd.read_csv(\"ungrouped_staff.txt\", encoding='utf-8')\n",
    "\n",
    "# Create the table with the desired columns\n",
    "df_STAFF = df_STAFF[columns]\n",
    "\n",
    "# Round the values to one decimal point\n",
    "df_STAFF = df_STAFF.round(decimals=1)\n",
    "\n",
    "# Create a Staff dummy variable where Staff = 1\n",
    "df_STAFF['Volunteer'] = 0\n",
    "df_STAFF['Staff'] = 1\n",
    "df_STAFF['Position'] = 'Staff'\n",
    "\n",
    "# Merge the two dataframes\n",
    "df_VOLandSTAFF = pd.concat([df_VOL, df_STAFF], ignore_index=True)\n",
    "\n",
    "df_VOLandSTAFF.shape\n",
    "#df_VOLandSTAFF.to_excel('ungrouped_ALL.xlsx', index=False)\n",
    "df_VOLandSTAFF.to_csv('ungrouped_ALL.txt', index=False)\n",
    "\n",
    "df_VOLandSTAFF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d614b44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataframe saved to Individual.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10465 entries, 0 to 10583\n",
      "Data columns (total 45 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Team Name         10465 non-null  object \n",
      " 1   Survey Data       10465 non-null  object \n",
      " 2   Well-being        10465 non-null  float64\n",
      " 3   Needs             10465 non-null  float64\n",
      " 4   Engagement        10465 non-null  float64\n",
      " 5   Autonomy          10465 non-null  float64\n",
      " 6   Belonging         10465 non-null  float64\n",
      " 7   Competence        10465 non-null  float64\n",
      " 8   Leadership        10465 non-null  float64\n",
      " 9   Management        10465 non-null  float64\n",
      " 10  Returns           10465 non-null  float64\n",
      " 11  Rewards           10465 non-null  float64\n",
      " 12  Status            10465 non-null  float64\n",
      " 13  Myself            10465 non-null  int64  \n",
      " 14  Tasks             10465 non-null  int64  \n",
      " 15  Free              10465 non-null  int64  \n",
      " 16  Mastery           10465 non-null  int64  \n",
      " 17  Competent         10465 non-null  int64  \n",
      " 18  Learn             10465 non-null  int64  \n",
      " 19  Group             10465 non-null  int64  \n",
      " 20  Talk              10465 non-null  int64  \n",
      " 21  Care              10465 non-null  int64  \n",
      " 22  Satisfied         10465 non-null  int64  \n",
      " 23  Meaning           10465 non-null  int64  \n",
      " 24  Stay              10465 non-null  int64  \n",
      " 25  Ideas             10465 non-null  int64  \n",
      " 26  Values            10465 non-null  int64  \n",
      " 27  Understands       10465 non-null  int64  \n",
      " 28  Encourages        10465 non-null  int64  \n",
      " 29  Listens           10465 non-null  int64  \n",
      " 30  Network           10465 non-null  int64  \n",
      " 31  Friendly          10465 non-null  int64  \n",
      " 32  Team              10465 non-null  int64  \n",
      " 33  Appreciated       10465 non-null  int64  \n",
      " 34  Responsibilities  10465 non-null  int64  \n",
      " 35  Work              10465 non-null  int64  \n",
      " 36  Impact            10465 non-null  int64  \n",
      " 37  Strong            10465 non-null  int64  \n",
      " 38  Drained           10465 non-null  int64  \n",
      " 39  Frustrated        10465 non-null  int64  \n",
      " 40  Volunteer         10465 non-null  int64  \n",
      " 41  Staff             10465 non-null  int64  \n",
      " 42  Position          10465 non-null  object \n",
      " 43  Country           10465 non-null  object \n",
      " 44  Region            10465 non-null  object \n",
      "dtypes: float64(11), int64(29), object(5)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# STEP 3\n",
    "# Assign Country and Region based on Team Name\n",
    "# 3.1 Assign a country to each team\n",
    "# 3.2 Assign a region to each country\n",
    "\n",
    "with open(\"Team_Country_Region_allocation.py\", encoding='utf-8') as file:\n",
    "    exec(file.read())\n",
    "\n",
    "# output file: 'Individual.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c3404e4-0e15-449a-a7e3-12bde8e79ff0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Country  size (n)\n",
      "5     Bahamas         2\n",
      "17  Indonesia         1\n",
      "33     Serbia         1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47 entries, 0 to 46\n",
      "Data columns (total 81 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Region                   47 non-null     object \n",
      " 1   Country                  47 non-null     object \n",
      " 2   Position                 47 non-null     object \n",
      " 3   size (n)                 47 non-null     int64  \n",
      " 4   nTeams                   47 non-null     int64  \n",
      " 5   Well-being_mean          47 non-null     float64\n",
      " 6   Needs_mean               47 non-null     float64\n",
      " 7   Engagement_mean          47 non-null     float64\n",
      " 8   Autonomy_mean            47 non-null     float64\n",
      " 9   Belonging_mean           47 non-null     float64\n",
      " 10  Competence_mean          47 non-null     float64\n",
      " 11  Leadership_mean          47 non-null     float64\n",
      " 12  Management_mean          47 non-null     float64\n",
      " 13  Returns_mean             47 non-null     float64\n",
      " 14  Rewards_mean             47 non-null     float64\n",
      " 15  Status_mean              47 non-null     float64\n",
      " 16  Myself_mean              47 non-null     float64\n",
      " 17  Tasks_mean               47 non-null     float64\n",
      " 18  Free_mean                47 non-null     float64\n",
      " 19  Mastery_mean             47 non-null     float64\n",
      " 20  Competent_mean           47 non-null     float64\n",
      " 21  Learn_mean               47 non-null     float64\n",
      " 22  Group_mean               47 non-null     float64\n",
      " 23  Talk_mean                47 non-null     float64\n",
      " 24  Care_mean                47 non-null     float64\n",
      " 25  Satisfied_mean           47 non-null     float64\n",
      " 26  Meaning_mean             47 non-null     float64\n",
      " 27  Stay_mean                47 non-null     float64\n",
      " 28  Ideas_mean               47 non-null     float64\n",
      " 29  Values_mean              47 non-null     float64\n",
      " 30  Understands_mean         47 non-null     float64\n",
      " 31  Encourages_mean          47 non-null     float64\n",
      " 32  Listens_mean             47 non-null     float64\n",
      " 33  Network_mean             47 non-null     float64\n",
      " 34  Friendly_mean            47 non-null     float64\n",
      " 35  Team_mean                47 non-null     float64\n",
      " 36  Appreciated_mean         47 non-null     float64\n",
      " 37  Responsibilities_mean    47 non-null     float64\n",
      " 38  Work_mean                47 non-null     float64\n",
      " 39  Impact_mean              47 non-null     float64\n",
      " 40  Strong_mean              47 non-null     float64\n",
      " 41  Drained_mean             47 non-null     float64\n",
      " 42  Frustrated_mean          47 non-null     float64\n",
      " 43  Well-being_median        47 non-null     float64\n",
      " 44  Needs_median             47 non-null     float64\n",
      " 45  Engagement_median        47 non-null     float64\n",
      " 46  Autonomy_median          47 non-null     float64\n",
      " 47  Belonging_median         47 non-null     float64\n",
      " 48  Competence_median        47 non-null     float64\n",
      " 49  Leadership_median        47 non-null     float64\n",
      " 50  Management_median        47 non-null     float64\n",
      " 51  Returns_median           47 non-null     float64\n",
      " 52  Rewards_median           47 non-null     float64\n",
      " 53  Status_median            47 non-null     float64\n",
      " 54  Myself_median            47 non-null     float64\n",
      " 55  Tasks_median             47 non-null     float64\n",
      " 56  Free_median              47 non-null     float64\n",
      " 57  Mastery_median           47 non-null     float64\n",
      " 58  Competent_median         47 non-null     float64\n",
      " 59  Learn_median             47 non-null     float64\n",
      " 60  Group_median             47 non-null     float64\n",
      " 61  Talk_median              47 non-null     float64\n",
      " 62  Care_median              47 non-null     float64\n",
      " 63  Satisfied_median         47 non-null     float64\n",
      " 64  Meaning_median           47 non-null     float64\n",
      " 65  Stay_median              47 non-null     float64\n",
      " 66  Ideas_median             47 non-null     float64\n",
      " 67  Values_median            47 non-null     float64\n",
      " 68  Understands_median       47 non-null     float64\n",
      " 69  Encourages_median        47 non-null     float64\n",
      " 70  Listens_median           47 non-null     float64\n",
      " 71  Network_median           47 non-null     float64\n",
      " 72  Friendly_median          47 non-null     float64\n",
      " 73  Team_median              47 non-null     float64\n",
      " 74  Appreciated_median       47 non-null     float64\n",
      " 75  Responsibilities_median  47 non-null     float64\n",
      " 76  Work_median              47 non-null     float64\n",
      " 77  Impact_median            47 non-null     float64\n",
      " 78  Strong_median            47 non-null     float64\n",
      " 79  Drained_median           47 non-null     float64\n",
      " 80  Frustrated_median        47 non-null     float64\n",
      "dtypes: float64(76), int64(2), object(3)\n",
      "memory usage: 29.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: Country tables, one for volunteers, one for staff and one for all.\n",
    "# unfinished: select Position=volunteers and then repeat for staff\n",
    "\n",
    "df = pd.read_csv(\"Individual.csv\", encoding='utf-8')\n",
    "\n",
    "# STEP 4.1: Group rows by 'Country' and calculate size (count) for each group\n",
    "## for ALL, i.e. no more distinctions between volunteers and staff\n",
    "country_df = df.groupby(['Region', 'Country', 'Position']).size().reset_index(name='size (n)')\n",
    "\n",
    "# Filter numeric columns for mean and median calculations\n",
    "numeric_cols = df.select_dtypes(include='number').columns\n",
    "\n",
    "# Calculate the mean and median for each column\n",
    "mean_df = df.groupby(['Region', 'Country', 'Position'])[numeric_cols].mean().round(1).reset_index()\n",
    "median_df = df.groupby(['Region', 'Country', 'Position'])[numeric_cols].median().round(1).reset_index()\n",
    "\n",
    "# Count unique occurrences of 'Team Name' for each country\n",
    "n_teams_df = df.groupby(['Region', 'Country', 'Position'])['Team Name'].nunique().reset_index(name='nTeams')\n",
    "\n",
    "# Merge the size (count), mean, median, and nTeams DataFrames\n",
    "#country_df = country_df.merge(n_teams_df, on='Country').merge(mean_df, on='Country', suffixes=('_mean', '_median')).merge(median_df, on='Country', suffixes=('_mean', '_median'))\n",
    "\n",
    "# Merge the size (count), mean, median, and nTeams DataFrames on 'Country' and 'Position'\n",
    "country_df = country_df.merge(n_teams_df, on=['Region', 'Country', 'Position']) \\\n",
    "                       .merge(mean_df, on=['Region', 'Country', 'Position'], suffixes=('_mean', '_median')) \\\n",
    "                       .merge(median_df, on=['Region', 'Country', 'Position'], suffixes=('_mean', '_median'))\n",
    "\n",
    "# Clean staff and volnteer columns\n",
    "#country_df['Volunteer'] = country_df['Volunteer_median'].round(0).astype(int)\n",
    "#country_df['Staff'] = country_df['Staff_median'].round(0).astype(int)\n",
    "#country_df.shape\n",
    "\n",
    "# Drop useless columns from the DataFrame\n",
    "country_df = country_df.drop(columns=['Volunteer_median', 'Volunteer_mean','Staff_median', 'Staff_mean'])\n",
    "\n",
    "# STEP 4.2. Identify, and check illigitemate ballots where team size smaller than 4\n",
    "# there is a minor issue here - we drop teams < 4 after the groupby country.\n",
    "# so when we group by country from the Individual.csv dataset the dropped individuals \n",
    "# are included in the country means and median scores.\n",
    "# since the proportion of individuals that are dropped is small, we can ignore this issue for now.\n",
    "\n",
    "df = country_df\n",
    "df.shape\n",
    "\n",
    "# How many small teams are we talking about?\n",
    "dropped_small_teams_df = df[df['size (n)'] < 4][['Country', 'size (n)']].copy()\n",
    "print(dropped_small_teams_df)\n",
    "dropped_small_teams_df.shape\n",
    "\n",
    "# Drop illigitemate teams from country dataset\n",
    "df = df.drop(df[df['size (n)'] < 4].index)\n",
    "df.shape\n",
    "\n",
    "country_df.to_csv('Country.csv', index=False)\n",
    "country_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f732c9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5 Team tables, all respondents, volunteers and staff alike.\n",
    "\n",
    "# Group rows by 'Team Name' and calculate size (count) for each group\n",
    "df = pd.read_csv(\"Individual.csv\", encoding='utf-8')\n",
    "\n",
    "## for ALL, i.e. no more distinctions between volunteers and staff\n",
    "team_df = df.groupby(['Team Name', 'Country', 'Region', 'Position']).size().reset_index(name='size (n)')\n",
    "\n",
    "# Filter numeric columns for mean and median calculations\n",
    "numeric_cols = df.select_dtypes(include='number').columns\n",
    "\n",
    "# Calculate the mean and median for each column\n",
    "mean_df = df.groupby('Team Name')[numeric_cols].mean().round(1).reset_index()\n",
    "median_df = df.groupby('Team Name')[numeric_cols].median().round(1).reset_index()\n",
    "\n",
    "# Merge the size (count), mean, median, and nTeams DataFrames\n",
    "team_df = team_df.merge(mean_df, on='Team Name', suffixes=('_mean', '_median')).merge(median_df, on='Team Name', suffixes=('_mean', '_median'))\n",
    "\n",
    "# Clean staff and volnteer columns\n",
    "team_df['Volunteer'] = team_df['Volunteer_median'].round(0).astype(int)\n",
    "team_df['Staff'] = team_df['Staff_median'].round(0).astype(int)\n",
    "# Drop useless columns from the DataFrame\n",
    "team_df = team_df.drop(columns=['Volunteer_median', 'Volunteer_mean','Staff_median', 'Staff_mean'])\n",
    "\n",
    "team_df.shape\n",
    "team_df.to_csv('Team.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01d53841-4ac7-46e8-baf6-e1bdb8723571",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Country  size (n)\n",
      "13  Indonesia         1\n",
      "22     Serbia         1\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: country tables, one for volunteers, one for staff and one for all.\n",
    "# STEP 3.VOL: country tables volunteers only\n",
    "\n",
    "# 3.1.VOL Group rows by 'Country' and calculate size (count) for each group\n",
    "df = pd.read_csv(\"Individual.csv\", encoding='utf-8')\n",
    "\n",
    "## for VOL, i.e.  volunteers only\n",
    "# Filter the dataframe for 'Position' = 'Volunteer'\n",
    "df = df[df['Position'] == 'Volunteer']\n",
    "country_df = df.groupby('Country').size().reset_index(name='size (n)')\n",
    "\n",
    "# Filter numeric columns for mean and median calculations\n",
    "numeric_cols = df.select_dtypes(include='number').columns\n",
    "\n",
    "# 3.2.VOL Calculate the mean and median for each column\n",
    "mean_df = df.groupby('Country')[numeric_cols].mean().reset_index()\n",
    "median_df = df.groupby('Country')[numeric_cols].median().reset_index()\n",
    "\n",
    "# 3.3.VOL Count unique occurrences of 'Team Name' for each country\n",
    "n_teams_df = df.groupby('Country')['Team Name'].nunique().reset_index(name='nTeams')\n",
    "\n",
    "# 3.4.ALL Merge the size (count), mean, median, and nTeams DataFrames\n",
    "country_df = country_df.merge(n_teams_df, on='Country').merge(mean_df, on='Country', suffixes=('_mean', '_median')).merge(median_df, on='Country', suffixes=('_mean', '_median'))\n",
    "\n",
    "country_df.shape\n",
    "\n",
    "# STEP 3.5.VOL  Identify, and check illigitamate survey ballots where team size smaller than 4\n",
    "# there is a logic issue here - we cannot get rid of teams < 4 after groupby country.\n",
    "# if we groupby country from the teamsALL dataset then the means and averages will be wrong...\n",
    "\n",
    "df = country_df\n",
    "\n",
    "# How many small teams are we talking about?\n",
    "dropped_small_teams_df = df[df['size (n)'] < 4][['Country', 'size (n)']].copy()\n",
    "print(dropped_small_teams_df)\n",
    "dropped_small_teams_df.shape\n",
    "\n",
    "# STEP 3.6.VOL  Drop from illigitamate teams from country dataset\n",
    "df = df.drop(df[df['size (n)'] < 4].index)\n",
    "df.shape\n",
    "\n",
    "# STEP 3.7.VOL  Export country-level aggregations to Excel\n",
    "#country_df.to_excel('country_VOL.xlsx', index=False)\n",
    "country_df.to_csv('country_VOL.txt', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a147e4e5-2afc-4f5a-9e5d-1a2cbe5a7b50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'country'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18044\\536821955.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mcountry_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'country'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'size (n)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# 3.4.ALL Merge the size (count), mean, median, and nTeams DataFrames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mcountry_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcountry_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_teams_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'country'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'country'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_mean'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_median'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmedian_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'country'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_mean'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_median'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcountry_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m  10828\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMergeValidate\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10829\u001b[0m     ) -> DataFrame:\n\u001b[0;32m  10830\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10832\u001b[1;33m         return merge(\n\u001b[0m\u001b[0;32m  10833\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10834\u001b[0m             \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10835\u001b[0m             \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         )\n\u001b[0;32m    169\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         op = _MergeOperation(\n\u001b[0m\u001b[0;32m    171\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    790\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m         ) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_drop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1293\u001b[0m                         \u001b[1;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m                         \u001b[1;31m#  the latter of which will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1297\u001b[1;33m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1298\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m                             \u001b[1;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1908\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1910\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1911\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1914\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'country'"
     ]
    }
   ],
   "source": [
    "# STEP 3: country tables, one for volunteers, one for staff and one for all.\n",
    "# STEP 3.STAFF: country tables staff only\n",
    "\n",
    "# 3.1.STAFF Group rows by 'Country' and calculate size (count) for each group\n",
    "if 'country' in df.columns:\n",
    "    country_df = df.groupby('country').size().reset_index(name='size (n)')\n",
    "else:\n",
    "    country_df = pd.DataFrame(columns=['country', 'size (n)'])\n",
    "\n",
    "# 3.4.ALL Merge the size (count), mean, median, and nTeams DataFrames\n",
    "country_df = country_df.merge(n_teams_df, on='country').merge(mean_df, on='country', suffixes=('_mean', '_median')).merge(median_df, on='country', suffixes=('_mean', '_median'))\n",
    "\n",
    "\n",
    "print(country_df.shape)\n",
    "\n",
    "# STEP 3.5.STAFF  Identify, and check illigitamate survey ballots where team size smaller than 4\n",
    "# there is a logic issue here - we cannot get rid of teams < 4 after groupby country.\n",
    "# if we groupby country from the teamsALL dataset then the means and averages will be wrong...\n",
    "\n",
    "df = country_df\n",
    "\n",
    "# How many small teams are we talking about?\n",
    "dropped_small_teams_df = df[df['size (n)'] < 4][['country', 'size (n)']].copy()\n",
    "print(dropped_small_teams_df)\n",
    "dropped_small_teams_df.shape\n",
    "\n",
    "# STEP 3.6.STAFF  Drop from illigitamate teams from country dataset\n",
    "df = df.drop(df[df['size (n)'] < 4].index)\n",
    "df.shape\n",
    "\n",
    "# STEP 3.7.STAFF  Export country-level aggregations to Excel\n",
    "#country_df.to_excel('country_STAFF.xlsx', index=False)\n",
    "country_df.to_csv('country_STAFF.txt', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef4812cc-b953-4bc3-be9c-a80b2fdcdc8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10465 entries, 0 to 10464\n",
      "Data columns (total 45 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Team Name         10465 non-null  object \n",
      " 1   Survey Data       10465 non-null  object \n",
      " 2   Well-being        10465 non-null  float64\n",
      " 3   Needs             10465 non-null  float64\n",
      " 4   Engagement        10465 non-null  float64\n",
      " 5   Autonomy          10465 non-null  float64\n",
      " 6   Belonging         10465 non-null  float64\n",
      " 7   Competence        10465 non-null  float64\n",
      " 8   Leadership        10465 non-null  float64\n",
      " 9   Management        10465 non-null  float64\n",
      " 10  Returns           10465 non-null  float64\n",
      " 11  Rewards           10465 non-null  float64\n",
      " 12  Status            10465 non-null  float64\n",
      " 13  Myself            10465 non-null  int64  \n",
      " 14  Tasks             10465 non-null  int64  \n",
      " 15  Free              10465 non-null  int64  \n",
      " 16  Mastery           10465 non-null  int64  \n",
      " 17  Competent         10465 non-null  int64  \n",
      " 18  Learn             10465 non-null  int64  \n",
      " 19  Group             10465 non-null  int64  \n",
      " 20  Talk              10465 non-null  int64  \n",
      " 21  Care              10465 non-null  int64  \n",
      " 22  Satisfied         10465 non-null  int64  \n",
      " 23  Meaning           10465 non-null  int64  \n",
      " 24  Stay              10465 non-null  int64  \n",
      " 25  Ideas             10465 non-null  int64  \n",
      " 26  Values            10465 non-null  int64  \n",
      " 27  Understands       10465 non-null  int64  \n",
      " 28  Encourages        10465 non-null  int64  \n",
      " 29  Listens           10465 non-null  int64  \n",
      " 30  Network           10465 non-null  int64  \n",
      " 31  Friendly          10465 non-null  int64  \n",
      " 32  Team              10465 non-null  int64  \n",
      " 33  Appreciated       10465 non-null  int64  \n",
      " 34  Responsibilities  10465 non-null  int64  \n",
      " 35  Work              10465 non-null  int64  \n",
      " 36  Impact            10465 non-null  int64  \n",
      " 37  Strong            10465 non-null  int64  \n",
      " 38  Drained           10465 non-null  int64  \n",
      " 39  Frustrated        10465 non-null  int64  \n",
      " 40  Volunteer         10465 non-null  int64  \n",
      " 41  Staff             10465 non-null  int64  \n",
      " 42  Position          10465 non-null  object \n",
      " 43  Country           10465 non-null  object \n",
      " 44  Region            10465 non-null  object \n",
      "dtypes: float64(11), int64(29), object(5)\n",
      "memory usage: 3.6+ MB\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Team Name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18044\\180619887.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mteam_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Team Name'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'size (n)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# STEP 4.2  Merge the size (count), mean, median, and country DataFrames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mteam_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mteam_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Team Name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_mean'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_median'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmedian_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Team Name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_mean'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_median'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Team Name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'country'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Position'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Team Name'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mteam_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mteam_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'team_ALL.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m  10828\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMergeValidate\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10829\u001b[0m     ) -> DataFrame:\n\u001b[0;32m  10830\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10832\u001b[1;33m         return merge(\n\u001b[0m\u001b[0;32m  10833\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10834\u001b[0m             \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10835\u001b[0m             \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         )\n\u001b[0;32m    169\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         op = _MergeOperation(\n\u001b[0m\u001b[0;32m    171\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    790\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m         ) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_drop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1293\u001b[0m                         \u001b[1;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m                         \u001b[1;31m#  the latter of which will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1297\u001b[1;33m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1298\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m                             \u001b[1;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gabriel.pictet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1908\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1910\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1911\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1914\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Team Name'"
     ]
    }
   ],
   "source": [
    "# STEP 4: create dataframe where one row is one team\n",
    "\n",
    "# STEP 4.1 Group rows by 'Team Name' and calculate size (count) for each team\n",
    "# Load the dataframe from \"ungrouped_ALL_with_regions.txt\"\n",
    "file_path = \"Individual.csv\"\n",
    "df = pd.read_csv(file_path, sep=\",\", encoding='utf-8')\n",
    "\n",
    "df.info()\n",
    "team_df = df.groupby('Team Name').size().reset_index(name='size (n)')\n",
    "\n",
    "\n",
    "# STEP 4.2  Merge the size (count), mean, median, and country DataFrames\n",
    "team_df = team_df.merge(mean_df, on='Team Name', suffixes=('_mean', '_median')).merge(median_df, on='Team Name', suffixes=('_mean', '_median')).merge(df[['Team Name', 'country', 'Position']].drop_duplicates(), on='Team Name')\n",
    "team_df.info()\n",
    "team_df.to_csv('team_ALL.txt', index=False)\n",
    "\n",
    "## create an short table without survey results\n",
    "#team_df = team_df.merge(df[['Team Name', 'Country', 'Position']].drop_duplicates(), on='Team Name')\n",
    "#team_df.to_csv('team_ALL_short.txt', index=False)\n",
    "#team_df.info()\n",
    "\n",
    "# STEP 4.3  \n",
    "# For ALL (Volunteers and staff) - create files with Teams data\n",
    "#team_df.to_excel('team_ALL.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4997148-a346-4651-b438-40267ff94dca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
